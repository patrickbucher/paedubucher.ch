<?xml version="1.0" ?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>paedubucher.ch</title>
    <subtitle>paedubucher.ch Article Feed</subtitle>
    <link href="https://paedubucher.ch/atom.xml" rel="self"/>
    <link href="https://paedubucher.ch/"/>
    <id>https://paedubucher.ch/</id>
    <updated>2020-09-16T20:18:51.798133Z</updated>
    <entry>
        <title>Compose Key on X</title>
        <link href="https://paedubucher.ch/articles/2020-09-16-compose-key-on-x.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-09-16-compose-key-on-x.html</id>
        <updated>2020-09-16T21:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
I've been using the Swiss keyboard layout for most of my life. Things changed
when I first had to work on a Mac Book. If the Swiss keyboard layout is not
great for programming on a usual keyboard, because it requires combinations with
Alt-Gr to type in braces and brackets, I consider the Mac version of it outright
horrible, because braces and brackets are located on the digits row. Those
symbols are not even painted onto their respective keys, which makes the
transition for non-Mac users even harder.

# Entering the US Keyboard Layout

So instead of learning an additional inefficient way of typing special
characters, I decided to adopt to the US keyboard layout. This layout gives you
most characters required for programming with a single key or a combination of
Shift and another key.

One issue of the US layout is that it doesn't provide characters such as `ö` or
`é`, which I still need to type in emails and for documentation. Mac OS provides
a composing mechanism that lets you type a double quote followed by a
letter like `o`, and then combines those characters to the German umlaut `ö`. If
you just want to type a double quotation mark, you need to type Space right
after it, so that the quotation mark is not attempted to be combined with the
next character entered. This is annoying, of course, when programming. So I
never really got warm with Mac keyboards. An external keyboard with US layout
didn't help much in that respect, but at least allowed me to type those
cumbersome combinations faster and more precisely.

# Switching Keyboard Layouts

Another solution to the goal conflict of typing German umlauts and special
programming characters as fast as possible is to switch the keyboard layout as
needed. I'm very familier with this approach, because I use the Russian keyboard
layout once in a while. I modified my [dwm](http://dwm.suckless.org/)
configuration so that pressing Super+Tab changes my keyboard layout using the
following script (`switchkb`):

    #!/bin/sh

    layout=&quot;$(setxkbmap -query | grep layout | egrep -o [a-z]{2}$)&quot;
    if [ &quot;$layout&quot; == &quot;ch&quot; ]; then
        setxkbmap ru
    elif [ &quot;$layout&quot; = &quot;ru&quot; ]; then
        setxkbmap us 
    elif [ &quot;$layout&quot; = &quot;us&quot; ]; then
        setxkbmap ch
    fi

This lets me cycle through the keyboard layouts I need very quickly. I also
display the keyboard layout in my status bar using
[slstatus](http://tools.suckless.org/slstatus/), which I described in a
[previous
article](https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html).
Even though this is a feasible solution, I still have to switch mentally between
the Swiss German and the US keyboard layout. Typing a double quote in a German
email requires me to press another key than typing that very same character
when programming. This additional mental burden is wearing me down on a usual
working day, which consists of roughly 70% programming and 30% communicating.
The communication part might actually be bigger, but some of the communication
also takes part in English, so that I'd be better off using the US rather than
the Swiss German keyboard layout.

Typing cyrillic letters still requires the Russian keyboard layout, so I won't
get rid of my `switchkb` script and Super+Tab. However, since typing punctuation
marks using the Russian keyboard layout is almost the same as typing those
characters on the US keyboard layout, I rather ditch my native Swiss German
layout and embrace the imperialistic option.

# Composing Characters

While being able to write source code faster and not having to distinguish
between English, German, and Russian when typing punctuation marks sounds great
in terms of _efficiency_, not typing in the typographically correct
representations of German umlauts (_Ae_, _Oe_, _Ue_ instead of _Ä_, _Ö_, _Ü_) or
misspelling french words with accent marks (_depecherent_ instead of
_dépêchèrent_) is bad in terms of communicating _effectively_. So there must be
at least a way to type those characters somewhat efficiently.

One option would be to type those characters as hexadecimal Unicode code points.
I've already learned a few thereof by heart, such as U+2012, U+2013, and U+2014
for dashes of different lenghts, or simple to remember ones like U+00ab and
U+00bb for guillemets (_«»_). In `vim`, those sequences can be entered by
presing Ctrl+V followed by the part after U+. In GTK applications, Ctrl+U enters
a mode to enter those codes to be finished with a Space (or maybe some other
character not representing a hexadecimal digit). However, remembering a lot of
Unicode code points is not a very intuitive way to type and probably leads to a
lot of lookups on [FileFormat.Info](https://www.fileformat.info), which is at
least a more sophisticated way than just googling those character code points,
which usually ends up on FileFormat.Info anyway, or, worse, on a big Wikipedia
page discussing the history and cultural significance of the `LATIN SMALL LETTER
C WITH CEDILLA` (ç) before giving me it's code point U+00E7.

## Entering the Compose Key

A better option is certainly the _Compose Key_. (Check out this [Wikipedia
Article](https://en.wikipedia.org/wiki/Compose_key) for a discussion of its
history and cultural significance). Even though not even the nerdiest of nerd
keyboards come with a physical compose key nowadays, the X Window System still
supports the underlying mechanism. And since X is running on both my Linux and
OpenBSD computers, using its compose key mechanism helps me both at work and for
my private computing, the latter consisting mostly of writing articles about
entering special characters on special computing setups and the like.

A good reference for this mechanism is the manual page `Compose(5)` or
`XCompose(5)` on both GNU/Linux and OpenBSD. (I guess it also applies to
FreeBSD, but I didn't check yet). However, there's some additional information
required to do a basic setup, so here's a quick guide.

First, a compose key needs to be picked. There are various options, which can be
looked up as follows:

    # OpenBSD
    $ grep 'compose:' /usr/X11R6/share/X11/xkb/rules/base.lst

    # Arch Linux
    $ grep 'compose:' /usr/share/X11/xkb/rules/base.lst

Which shows a list of keys that could be used for the compose key:

      compose:ralt         Right Alt
      compose:lwin         Left Win
      compose:lwin-altgr   3rd level of Left Win
      compose:rwin         Right Win
      compose:rwin-altgr   3rd level of Right Win
      compose:menu         Menu
      compose:menu-altgr   3rd level of Menu
      compose:lctrl        Left Ctrl
      compose:lctrl-altgr  3rd level of Left Ctrl
      compose:rctrl        Right Ctrl
      compose:rctrl-altgr  3rd level of Right Ctrl
      compose:caps         Caps Lock
      compose:caps-altgr   3rd level of Caps Lock
      compose:102          &amp;lt;Less/Greater&amp;gt;
      compose:102-altgr    3rd level of &amp;lt;Less/Greater&amp;gt;
      compose:paus         Pause
      compose:prsc         PrtSc
      compose:sclk         Scroll Lock

Caps Lock is a good choice, but would make it harder to type anonymous hate mail
in all-caps to people not agreeing on my operating system preferences.
Therefore I pick the Menu key, which I didn't even use once in my dark Windows
days. The compose key can be defined in `~/.xinitrc`, ideally together with the
choice of the aforementioned imperialistic keyboard layout:

    setxkbmap us
    setxkbmap -option compose:menu

On my Thinkpad, I prefer the PrtSc key, which is placed between AltGr and Ctrl
on the right hand side of the Space bar. I don't often take screenshots, since the
content of my screen is mostly text, which is better captured using primary
selection. (Did I already mention that I use Arch, btw.?)

    setxkbmap us
    setxkbmap -option compose:prtsc

After restarting X, the compose key is already ready for action. Now I can type
`Menu &quot; O` to enter _Ö_ on my PC (OpenBSD), or `PrtSc ' e` to enter _é_. Not all
together at the same time, but as a sequence, which is much more convenient.
Pre-defined sequences can be looked up in the compose files under
`/usr/X11/share/X11/locale/[locale]/Compose` for OpenBSD, or
`/us/share/X11/locale/[locale]/Compose` on Arch Linux, respectively. As locale,
I simply use `en_US.UTF-8` (imperialism, remember?), which gives me a wide range
of sequences (hand-picked examples):

    &lt;Multi_key&gt; &lt;C&gt; &lt;o&gt; 			: &quot;©&quot;   copyright # COPYRIGHT SIGN
    &lt;Multi_key&gt; &lt;R&gt; &lt;o&gt; 			: &quot;®&quot;   registered # REGISTERED SIGN
    &lt;Multi_key&gt; &lt;plus&gt; &lt;minus&gt;     	: &quot;±&quot;   plusminus # PLUS-MINUS SIGN
    &lt;Multi_key&gt; &lt;s&gt; &lt;s&gt;            	: &quot;ß&quot;   ssharp # LATIN SMALL LETTER SHARP S
    &lt;Multi_key&gt; &lt;E&gt; &lt;equal&gt;        	: &quot;€&quot;   EuroSign # EURO SIGN
    &lt;Multi_key&gt; &lt;u&gt; &lt;slash&gt; 		: &quot;µ&quot;   mu # MICRO SIGN
    &lt;Multi_key&gt; &lt;quotedbl&gt; &lt;A&gt;     	: &quot;Ä&quot;   Adiaeresis # LATIN CAPITAL LETTER A WITH DIAERESIS
    &lt;Multi_key&gt; &lt;acute&gt; &lt;E&gt;        	: &quot;É&quot;   Eacute # LATIN CAPITAL LETTER E WITH ACUTE
    &lt;Multi_key&gt; &lt;asciitilde&gt; &lt;N&gt;   	: &quot;Ñ&quot;   Ntilde # LATIN CAPITAL LETTER N WITH TILDE
    &lt;Multi_key&gt; &lt;comma&gt; &lt;c&gt;        	: &quot;ç&quot;   ccedilla # LATIN SMALL LETTER C WITH CEDILLA
    &lt;Multi_key&gt; &lt;v&gt; &lt;z&gt; 			: &quot;ž&quot;   U017E # LATIN SMALL LETTER Z WITH CARON

Those sequences are very intuitive to type, so looking them up will hardly be
needed. This configuration also allows me to type scientific transliterations of
Russian words, such as _Č_ in _Čechov_ (`Menu &lt; C`) instead of the German _Tschechow_
or the English _Chekov_. Same with _š_ in _Puškin_ and _Ž_ in _Dr. Živago_.

If those sequences do not suffice for one's particular needs, more sequences can
be defined in the file `~/.XCompose`. When doing so, it is important to also
include the original definitions mentioned above as follows, so that it's not
needed to re-define them all:

    include &quot;%S/en_US.UTF-8/Compose&quot;

The `%S` resolves to the path `/usr/X11R6/share/X11/locale` on OpenBSD and
`/usr/share/X11/locale` on GNU/Linux. (`%L` would resolve to the current
locale.) Additional rules can be defined as follows:

    &lt;Multi_key&gt; &lt;colon&gt; &lt;minus&gt; &lt;parenright&gt; : &quot;☺&quot; U263A # WHITE SMILING FACE

This allows to type the smiley using `Menu : - )` on my OpenBSD machine. It is
also possible to enter whole strings in that manner:

    &lt;Multi_key&gt; &lt;m&gt; &lt;a&gt; &lt;c&gt; : &quot;fanboy&quot;

Whose effect I leave for you to figure out.
</content>
    </entry>
    <entry>
        <title>OpenBSD on the Desktop (Part II)</title>
        <link href="https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html</id>
        <updated>2020-09-12T15:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
A week ago, I've installed [OpenBSD on my
Thinkpad](/articles/2020-09-05-openbsd-on-the-desktop-part-i.html). I've been
using it now and then, and already have changed a couple of things in respect to
the original setup described in the article. I also installed OpenBSD on the
Dell Optiplex on which I [previously installed
FreeBSD](/articles/2020-08-11-freebsd-on-the-desktop-part-i.html) a month
before. This means that I'm no longer using FreeBSD on the desktop, at least not
for the moment. However, FreeBSD is running on a disk station I built earlier
this summer. Maybe I'll describe that particular setup (using ZFS) in a later
article.

Except for that storage server, I'd like to use OpenBSD for most of my private
computing. In this article, I describe some GUI tweaks and additional setup
tasks I perfmormed in order to feel more at home on my OpenBSD machines. Some of
the tasks performed are _not_ specific to OpenBSD, but could also be applied to
a Linux setup.

# doas

`sudo` originally came from the OpenBSD community. It is almost as widely used
in the Unix world as SSH, which is the most prominent OpenBSD project.  However,
`sudo` became bigger and harder to configure. Therefore, Ted Unangst came up
with a simpler alternative called `doas`, which stands for _Dedicated OpenBSD
Application Subexecutor_. `doas` is less powerful than `sudo`, but much smaller,
easier to configure, and, thus, more secure. The full rationale can be read in
[Ted Unangst's Blog](https://flak.tedunangst.com/post/doas).

A basic `doas` setup requires to login as root for one last time. The
configuration shall be kept extremely simple. I'd like to permit all users from
the `wheel` group (which is just me on my computers) to use `doas` without
entering the password every time but only once when executing a command that
requires `root` permissions. This is only a single line in `/etc/doas.conf`:

    permit persist :wheel    

Let's check this setup by logging in as a user of the wheel group and trying to
update the packages:

    $ doas pkg_add -u

This works, so bye bye `root` account.

# Fonts for dwm, dmenu, and st

By default, `dwm`, `dmenu`, and `st` use a monospace font of size 10, or
pixelsize 12, respectively, which is hard to read on a screen with a high
resolution. On Linux, I use the the TrueType font DejaVu Sans Mono. For OpenBSD,
I'd rather use something more minimalistic: the [Terminus bitmap
font](http://terminus-font.sourceforge.net/).

As `pkg_info -Q terminus` shows, this font comes in different versions. I prefer
the version with the centered tilde, which I install:

    $ doas pkg_add terminus-font-4.47p0-centered_tilde

Let's reconfigure `st` first, for testing changes doesn't require a restart of
the window manager. I stored my suckless sources in `~/suckless`, so the
font for `st` can be configured in `~/suckless/config.h`. I replace the existing
font configuration

    static char *font = &quot;Liberation Mono:pixelsize=12:antialias=true:autohint=true&quot;;

with

    static char *font = &quot;Terminus:pixelsize=24&quot;;

The options `antialias` and `autohinting` are not needed for a bitmap font, so I
left them away. 24 pixels is rather big, but my screen is big enough to show two
text editors with more than 80 characters per line next to each other, so let's
keep it this way. I rebuild and reinstall `st`, then switch to `dwm`:

    $ doas make install
    $ cd ../dwm

The font configuration in the `config.h` file looks a bit different here:

    static const char *fonts =      { &quot;monospace:size=10&quot; };
    static const char dmenufont =   &quot;monospace:size=10&quot;;

Let's just use the same font as for `st` here:

    static const char *fonts =      { &quot;Terminus:pixelsize=24&quot; };
    static const char dmenufont =   &quot;Terminus:pixelsize=24&quot;;

Note that I'm using `pixelsize` instead of `size` here. (24pt would be much
bigger than 24px.) Then I rebuild and reinstall `dwm`.

    # make install

This configuration appllies also to `dmenu` and `slstatus`, so we're done with
the fonts.

# X Background

By default, the desktop background is a pattern of black and grey dots, which is
a strain to the eye. Even though I rarely look at an empty desktop for long, I'd
rather change this to a solid color. This can be done by adding a command to
`~/.xinitrc`:

    xsetroot -solid black

Right before `dwm` is executed.

# USB Flash Drive

Even though SSH is almost ubiquitous nowadays, a USB flash drive is still useful
when it comes to exchanging data between computers, especially if Windows is
involved, or if the network does not allow SSH.

Block storage devices are accessible through the device nodes `/dev/sd*`,
whereas `*` stands for the number of the disk. The disks can be listed as
follows:

    $ sysctl hw.disknames
    hw.disknames=sd0:ef0268c97ae7a246

Only `sd0` is active, even though I already plugged in my USB dongle. However,
the system already figured out that there is a second disk:

    $ sysctl hw.diskcount
    hw.diskcount=2

The next free disk would have the name `sd1`. The device nodes can be created by
running the `MAKEDV` script in `/dev`:

    $ cd /dev
    $ doas sh MAKEDEV sd1

Let's initialize a new MBR partition schema on `sd1`:

    $ doas fdisk -iy sd1

The new disk layout can be checked using `disklabel`:

    $ doas disklabel sd1
    # /dev/rsd1c
    ...

The first line of the output tells us that there's a partition under
`/dev/rsd1c`. (The `r` refers to «raw», as opposed to «block».) The partition
can be formatted using `newfs` by referring to that partition name:

    $ doas newfs sd1c

This creates a default FFS (Fast File System) partition, which is useful to
exchange data between BSD operating systems. The formatted partition is then
ready to be mounted:

    $ doas mount /dev/sd1c /mnt

## Other Partition Types

Other partition types are available under other utilities.

### FAT32

The following command creates a FAT32 partition:

    $ doas newfs_msdos -F 32 sd1c

The `-F 32` parameter specifies FAT32 (as opposed to FAT16 or FAT8). To mount
the partition, use the according `mount` command:

    $ doas mount_msdos /dev/sd1c /mnt

### EXT2

In order to create an `ext2fs` file system, the partition type needs to be
specified accordingly. First, you might consider a GPT partition schema instead
of MBR (additional `-g` parameter):

    $ doas fdisk -igy sd1

Then use `disklabel` interactively to define a new partition:

    $ doas disklabel -E sd1

First, delete all the partitions with `z`. Then, create a new partition with
`a`, and make sure to specify the type as `ext2fs` instead of the default
`4.2BSD`. Notice that the new partition has a different letter (say, `a`), so
you need to use `sd1a` instead of `sd1c` for the next steps. Write the changes
by typing `w`, then exit with `q`. Now you can format and mount the partition:

    $ doas newfs_ext2fs sd1a
    $ doas mount_ext2fs /dev/sd1a /mnt

# SSH Key (GitHub)

In order to access my GitHub repositories, I first create a new SSH key:

    $ ssh-keygen -t rsa -b 4096

Since I manage my passwords with `pass` (of which more later), I don't know most
of them by heart. So I can't just login to GitHub and add my public key.
Therefore, I copy my public key to my laptop, on which I'm already logged in to
GitHub.

This can be either done using `scp`, for which `sshd` has to be running on my
laptop (which currently has the IP `192.168.178.53`):

    $ scp ~/.ssh/id_rsa.pub 192.168.178.53:/home/patrick

Or using the USB flash drive formatted with `ext2` from before:

    $ doas newfs_ext2fs -I sd1a
    $ doas mount_ext2fs /dev/sd1a /mnt
    $ doas cp ~/.ssh/id_rsa.pub /mnt/

Then `id_rsa.pub` can be copied into the according [GitHub Settings
Page](https://github.com/settings/ssh/new), after which cloning GitHub
repositories should work on the OpenBSD machine:

    $ git clone git@github.com:patrickbucher/conf

# GPG Key

My passwords are encrypted using GPG. To encrypt them, I need to copy my private
key from my other machine. First, I list my private keys:

    $ gpg --list-keys --keyid-format SHORT
    pub   rsa2048/73CE6620 2016-11-11 [SC]
          22F91EE20D641CBCF5B8678E82B7FE3A73CE6620
    uid         [ultimate] Patrick Bucher &lt;patrick.bucher@mailbox.org&gt;
    sub   rsa2048/AF6246E3 2016-11-11 [E]

Then I export both public and private key to an according file using the armored
key format:

    $ gpg --export --armor 73CE6620 &gt; public.key
    $ gpg --export-secret-key --armor 73CE6620 &gt; private.key

The two key files can be copied via SSH or the USB flash disk again, which I
won't show here.

Back on my OpenBSD machine, I need to install GnuPG first, because OpenBSD only
has `signify` installed by default:

    $ doas pkg_add gnupg

I pick the 2.2 version. Now I can import my keys:

    $ gpg2 --import private.key
    $ gpg2 --import public.key

The key is not trusted so far, so I need to change that:

    $ gpg2 --edit-key 73CE6620
    &gt; trust
    &gt; 5
    &gt; y
    &gt; quit

5 stands for ultimate trust, which seems appropriate.

# Password Manager

I use `pass` as a password manager, which can be installed as the
`password_store` package in OpenBSD:

    $ doas pkg_add password-store

Now that I have both my GPG private key and a working SSH key for GitHub, I can
clone my passwords stored on a private GitHub repository:

    $ git clone git@github.com:patrickbucher/pass .password-store

Now I can copy my GitHub password to the clipboard as follows:

    $ pass -c github

# Aliases

I use a lot of aliases, such as `gcl` as a shortcut for `git clone`, and `gad`
for `git add`, etc. Since OpenBSD uses a Public Domain Korn Shell by default,
the `.bashrc` configuration from my Linux machines won't work here, unless I
switch to `bash`, which is not exactly the point of using OpenBSD.

I define my aliases in `~/.kshrc` (excerpt):

    alias gcl='git clone'
    alias gad='git add'

In order to load those settings, an according `ENV` parameter needs to be
defined in `~/.profile` (see `man 1 ksh` for details):

    export ENV=$HOME/.kshrc

After the next login, `~/.profile` is reloaded, and the aliases are ready to be
used.

# Conclusion

Not only is my enhanced setup now ready to do some serious work, but I also
increased my understanding of some OpenBSD subjects. There are still things to
be improved and to be understood, but my setup is now good enough so that I no
longer need a Linux machine running next to it. I'm looking forward to use and
learn about OpenBSD in the time to come. I'll write additional articles on the
subject as soon as I have enough subject material ready.
</content>
    </entry>
    <entry>
        <title>OpenBSD on the Desktop (Part I)</title>
        <link href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</id>
        <updated>2020-09-05T20:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
Let's install OpenBSD on a Lenovo Thinkpad X270. I used this computer for my
computer science studies. It has both Arch Linux and Windows 10 installed as
dual boot. Now that I'm no longer required to run Windows, I can ditch the dual
boot and install an operating system of my choice.

# Preparation

First, I grab my work Thinkpad running Arch Linux and some USB dongle big enough
for the [amd64 miniroot
image](https://cdn.openbsd.org/pub/OpenBSD/6.7/amd64/miniroot67.fs) (roughly
five megabytes, that is). This small image does not include the file sets, which
will be downloaded during installation instead. I also download the [SHA256
checksums](https://mirror.ungleich.ch/pub/OpenBSD/6.7/amd64/SHA256) from the
Swiss mirror, and verify the downloaded image, before I copy it on my dongle:

    $ sha256sum -c --ignore-missing SHA256 
    miniroot67.fs: OK
    $ sudo dd if=miniroot67.fs of=/dev/sda bs=1M

# Installation

The Thinkpad X270 is connected to my network through Ethernet. The WiFi firmware
usually needs to be installed separately, so only Ethernet will work out of the
box. The BIOS has UEFI activated. OpenBSD and UEFI has issues on older hardware
(at least on a 2014 Dell laptop I have), but let's try it on this laptop,
anyway.

I plug in the dongle prepared before, and start the computer. I interrupt
the regular boot with Enter and pick an alternative boot method by pressing F12.
Now I pick my USB dongle. After roughly a minute, the installer has been
started. Now I follow these steps:

- I choose the option `I` to install OpenBSD.
- For the keyboard layout, I pick `sg`, for Swiss German.
- As a hostname, I simply pick `x270`, because it's a Thinkpad X270, and I'm not
  very creative when it comes to naming things.
- From the available network options (`iwm0`: WiFi, `em0`: Ethernet, and
  `vlan0`: Virtual LAN), I pick `em0`.
- I try to get an IPv4 address over DHCP, which seems to work very quickly.
- Next, I type in my very secret root password twice.
- I do _not_ start `sshd` by default, because I don't need to connect to this
  machine through SSH. It's supposed to be a workstation, not a server.
- The X Window System should not be started by `xnodm(1)`, so I leave it to
  `no`.
- Neither do I want to change the default to `com0`.
- I set up my user `patrick` with my proper name `Patrick Bucher`, and a decent
  password.
- The time zone has been detected properly as `Europe/Zurich`, which I just
  leave the way it is.
- The installer detected two disks: `sd0` and `sd1`. Since `sd0` is the detected
  SSD in my laptop, the UEFI issue from my Dell laptop doesn't exist on this
  computer. I pick `sd0` for the root disk, since `sd1` is my USB dongle.
- I choose to use the whole disk with a GPT partitioning schema, because it's
  2020.
- An auto-allocated layout for `sd0` is presented. It looks decent to me, so I
  just go with that auto layout.
- I don't want to initialize another disk, so I just press Enter (`done`).
- Since the miniroot image does not come with the file sets, I pick `http` as
  the location for the sets.
- I don't use a proxy, and use the mirror `mirrog.ungleich.ch` and the server
  directory `pub/OpenBSD/6.7/amd64` as proposed.
- Next, I unselect the game sets by entering `-game*`. (I heard that they're not
  much fun to play.) I leave all the other sets activated, including the `x`
  sets, which will be required for the GUI later on.
- After those sets are installed, I press Enter (`done`). Now the installer
  performs various tasks, after which I choose to `halt` the computer. This
  gives me time to remove the USB dongle.

# First Boot

I now restart my laptop, and OpenBSD boots. This takes more time than booting
Arch Linux, which uses `systemd`, whereas OpenBSD uses `rc`, which performs the
startup tasks sequentially.

There's a message showing up that various firmware (`intel-firmware`,
`iwm-firmware`, `inteldrm-firmware`, `uvideo-firmware`, and `vmm-firmware`) has
been installed automatically. Very nice, indeed.

## WiFi Connection

Now that the `iwm-firmware` has been installed, I can connect right away to my
WiFi network `frzbxpdb5`. I create a file called `/etc/hostname.iwm0`, wich
`hostname` being a literal string, and `iwm0` being the WiFi network card. The
connection to my WiFi network consists of a single line:

    dhcp nwid frzbxpdb5 wpakey [my-wpakey]

Whereas `frzbxpdb5` is my WiFi network's ESSID, and `[my-wpakey]` needs to be
replaced by the actual WPA key.

Then the networking can be restarted for that device:

    # sh /etc/netstart iwm0

This script is kind enough to set the file permissions of `/etc/hostname.iwm0`
to `640`, and then connects to my WiFi network.

I unplug the Ethernet cable and `ping openbsd.org`, which works fine, even after
a restart.

# Installing the GUI

My GUI on Unix-like systems is based on the Dynamic Window Manager (`dwm`) and a
couple of other tools, such as `dmenu`, `st`, `slstatus`, `slock`, all created and
maintained by the [Suckless](http://suckless.org/) community.

This software doesn't come with configuration facilities, but needs to be
configured in the respective C header file `config.h`, and then re-compiled.
Even though OpenBSD offers `dwm` as a package, customizing and configuring that
window manager requires to build it from source.

## Building `dwm` and Friends

First, I need to install `git` to fetch the source code:

    # pkg_add git

Then I fetch the source code for `dwm`, `dmenu`, `st`, and `slstatus` from [Suckless](http://suckless.org/):

    $ git clone https://git.suckless.org/dwm
    $ git clone https://git.suckless.org/dmenu
    $ git clone https://git.suckless.org/st
    $ git clone https://git.suckless.org/slstatus

### Building `dwm`

Next, I try to build `dwm`:

    $ cd dwm
    $ make

This fails with an error message (`'ft2build.h' file not found`), which reminds
me of building `dwm` on FreeBSD roughly a month before. Since I can finde the
header file at another location:

    # find / -type f -name ft2build.h
    /usr/X11R6/include/freetype2/ft2build.h

I simply can modify the `config.mk` accordingly by changing

    FREETYPEINC = /usr/include/freetype2

to

    FREETYPEINC = $(X11INC}/freetype2

Actually, I only need to comment the above line, and uncomment the line below

    # OpenBSD (uncomment)

The Suckless folks obviously are friendly towards OpenBSD, which is also
noticable in other places (more evidence to be shown further below).

The next compilation attempt succeeds:

    $ make

So let's install `dwm`, too:

    # make install

By default, and as to be seen in `config.h`, the keyboard combination
`[Alt]+[Shift]+[Enter]` (deeply engraved into the muscle memories of many `dwm`
users) starts the `st` terminal. This will be built in a while. However, I
prefer to use the _Super_ or _Windows_ key instead of `Alt`, since the former
is of no use in OpenBSD, and the latter still comes in handy when working with
the emacs readline mode. Therefore, I change the `MODKEY` from

    #define MODKEY Mod1Mask

to

    #define MODKEY Mod4Mask

Then I rebuild and reinstall `dwm`:

    # make install

### Building `st`

Let's switch over to the `st` source directory and just try to compile it:

    $ cd ../st
    $ make

Here, we get a warning that the function `pledge` (an OpenBSD mitigation, which
is built into the `master` branch, but surrounded by an `ifdef` preprocessor
statement, so that it will only be compiled for OpenBSD) is imported implicitly.
Let's just ignore this warning for now.

What's worse, the compilation fails with the error message:

    ld: error: unable to find library -lrt

Here, the FAQ comes in handy, stating that

    If you want to compile st for OpenBSD you have to remove -lrt from
    config.mk, ...

Having done so in `config.mk`, `st` compiles without any further issues, and,
thus, can be rebuilt and installed:

    # make install

### Building `dmenu`

Even OpenBSD users with Suckless tools have to open another GUI application than
a terminal emulator once in a while. For this purpose, Suckless offers `dmenu`.
Let's switch over to it and compile it:

    $ cd ../dmenu
    $ make

Again, we have the issue with `ft2build.h`, which can be resolved as above with
`dwm`: by using the proper path for `FREETYPEINC` in `config.mk`. Afterwards,
the build succeeds, and `dmenu` can be installed:

    # make install

### Building `slstatus`

`dwm` has a status bar on the top right, which can be used to show various
information. I used to write some shell commands in `.xinitrc` to compose such a
status line, and then set it by `xset -b` once every five seconds or so. This
approach generates a multitude of processes every couple of seconds.

`slstatus` is a C programm that is capable of showing various kinds of more or
less useful information. Let's switch over to `slstatus` and see, what is
available in `config.def.h`:

    $ cd ../slstatus
    $ less config.def.h

The comments section lists different functions (`battery_perc` for the battery
percentage, `datetime` for date and time information, `temp` for thermal
information, etc.). I usually display the CPU load, the battery percentage, the
memory usage, the current keyboard layout, and the current date and time.

Before configuring those, let's try to compile `slstatus`:

    $ make

This worked fine, so let's configure the information to be displayed in
`config.h`:

    static const struct arg args[] = {
        /* function    format    argument */
        { datetime,    &quot;%s&quot;,     &quot;%F %T&quot; },
    };

This renders the current date as follows:

    $ date +&quot;%F %T&quot;
    2020-09-05 19:26:38

I also like to have the weekday included, but not the seconds, so I define a
different argument string:

    $ date +&quot;%a %Y-%m-%d %H:%M&quot;
    Sat 2020-09-05 19:27

That's better, so let's use it in `config.h` (surrounded with some spaces in the
format string):

    static const struct arg args[] = {
        /* function    format    argument */
        { datetime,    &quot; %s &quot;,   &quot;%a %Y-%m-%d %H:%M&quot; },
    };

The other settings I like to have do not require any arguments, at least not on
OpenBSD, so I only need to define a decent format string (with `|` as a
seperator) for those:

    static const struct arg args[] = {
        /* function    format           argument */
        { cpu_perc,     &quot; cpu: %s%% |&quot;, NULL },
        { battery_perc, &quot; bat: %s%% |&quot;, NULL },
        { ram_used,     &quot; mem: %s |&quot;,   NULL },
        { keymap,       &quot; %s |&quot;         NULL },
        { datetime,     &quot; %s &quot;,         &quot;%a %Y-%m-%d %H:%M&quot; },
    };

This actually compiles, so let's install it:

    # make install

## Configuring X Startup

Now that all software is compiled and installed, let's run X. To do so, a file
`.xinitrc` in the user's directory is required (`/home/patrick/.xinitrc`):

    setxkbmap ch
    slstatus &amp;
    exec dwm

This sets the keyboard map for X to Swiss German, starts `slstatus` in the
background, and then executes `dwm`.

X can now be started by typing `startx`. This is a bit cumbersome to type every
time, so let's define a symbolic link to it:

    # ln -s &quot;$(which startx)&quot; /usr/bin/x

Now let's start X:

    $ x

If everything was configured properly, `dwm` shows up, and the status line says
that the whole system only uses roughly 60 megabytes of RAM. That's slim. The
keyboard combinations to open `st` and `dmenu` work, too.

# Conclusion

Installing a basic GUI with Suckless software was a rather smooth experience on
OpenBSD. (For FreeBSD, I deliberately have chosen a rather fine-grained approach
to installing X packages, which caused some additional work.) However, various
settings require additional tweaking. I also didn't use audio yet, which require
the volume buttons to be configured accordingly in `dwm`.

I'll also need to setup `sudo` or `doas`. As a regular Linux user, I'm used to
`sudo`, of course, but the simplicity of `doas` is a good argument to try it as
an alternative.

But those are things I'd like to cover in an upcoming article.
</content>
    </entry>
    <entry>
        <title>FreeBSD on the Desktop</title>
        <link href="https://paedubucher.ch/articles/2020-08-11-freebsd-on-the-desktop.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-08-11-freebsd-on-the-desktop.html</id>
        <updated>2020-08-11T22:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
I'm a happy user of [Arch Linux](https://www.archlinux.org/) both on my private
computers and on my work laptop. I even managed to get through four years of
university with my setup, and only had to bring a Windows machine on some rare
occasions, even though some professors are openly hostile towards a Linux setup.
(It doesn't run Microsoft Project and the real Excel, after all…)

Recently, I got interested in the BSDs, especially in
[OpenBSD](https://www.openbsd.org/) and in [FreeBSD](https://www.freebsd.org/).
Even though OpenBSD with its minimalistic appeal is better suited to my taste,
I'm currently looking at FreeBSD for a couple of reasons. First, I have to
maintain a storage server (a FreeBSD box using ZFS) at work. Second, I've also
built up a storage server at home. FreeBSD gives me the things I need mostly out
of the box: ZFS with redundancy on really cheap hardware. And third, I just like
to learn new things.

# Why FreeBSD?

However, when it comes to learning new things in my spare time, I'd rather spend
my time on something that will be useful in the long run. I use the [Lindy
Effect](https://en.wikipedia.org/wiki/Lindy_effect) as a guide: Technologies
like Kubernetes, the latest JavaScript framework, or Web Assembly have only been
around for a couple of years, and it's possible that those will undergo major
changes or vanish alltogether as fast as they came. Older technologies _that are
still around nowadays_, on the other hand, can be expected to be around for many
more years. Examples are the C programming language, various Unix shells, and ‒
FreeBSD. (I also make exceptions to this rule now and then. For example, I
learned Go and Rust in the summers of 2018 and 2019, respectively. Go, which had
its 1.0 release earlier than Rust, proofed to be the more stable choice.)

FreeBSD is now more than 25 years old. Its roots, however, go back to AT&amp;T's
original Unix from the 1970s. (All the code has been replaced or rewritten
since.) Being old is not enough, of course; a technology is only worthwhile
learning if it is still alive. Even though FreeBSD is rarely on the front page
of [Hacker News](https://news.ycombinator.com/), it is still widely used.
[Netflix](https://papers.freebsd.org/2019/fosdem/looney-netflix_and_freebsd/)
streams videos through FreeBSD systems, and the operating system of the
PlayStation 4, [Orbis
OS](https://en.wikipedia.org/wiki/PlayStation_4_system_software), is based on
FreeBSD.

FreeBSD is not only likely to stay around for a long time, it probably also
won't undergo fundmental changes very soon or very often. One example is the
startup system of FreeBSD, which is still based on `init` and `rc` scripts.
Ubuntu, on the other side, switched from SysVinit to Upstart in 2006, and again
from Upstart to systemd in 2015. That is one init system to learn for a lifetime
(FreeBSD) vs. three in less than a decade (Ubuntu).

Documentation is another advantage of FreeBSD. Having a system that rarely
introduces breaking changes makes it easier and more worthwile to provide good
documentation. The FreeBSD team not only provides good [manual
pages](https://www.freebsd.org/cgi/man.cgi), but also a well curated
[FAQs](https://www.freebsd.org/doc/en_US.ISO8859-1/books/faq/), a
[Wiki](https://wiki.freebsd.org/), and the very useful
[Handbook](https://www.freebsd.org/doc/en_US.ISO8859-1/books/handbook/).
FreeBSD material has such a long shelf life so that it is even worthwhile to
print books about that operating system. I'm reading [Absolute
FreeBSD](https://nostarch.com/absfreebsd3) now (from front to back, that is).
Michael Warren Lucas, the author of this book, has written [even more
books](https://www.tiltedwindmillpress.com/product-category/tech/) on FreeBSD
(and OpenBSD), which are not only useful and of high-quality, but also
well-written and fun to read.

As I started to work with FreeBSD, I suddenly realized what the term
«distribution» is probably supposed to mean: Not just a bunch of software
cobbled together with more or less frequent upgrades, but an entire operating
system that not only provides working software, but also the means to build that
very software on a standard installation. (Such a system is technically
described as _self hosting_.) A kernel can be compiled and installed with a
single command. Thanks to the ports tree, the packages can be compiled easily
and in a consistent way. I haven't tried _all_ Linux distributions, of course,
but quality standards that high are certainly not the rule in the GNU/Linux
world. (Debian and Arch, the Linux distributions I use the most and know the
best, are still absolutely great operating systems.)

# FreeBSD on the Desktop?

It's safe to say that FreeBSD is a good choice for servers in a Unix
environment. But does it also work well on a desktop computer? And is it even an
option for the kind of desktop I like to run: not GNOE, KDE, or Xfce, but a
minimalistic setup based on [dwm](http://dwm.suckless.org/), which probably
isn't used by many. Since dwm can only be configured by modifying the `config.h`
file, I won't be able to use the version from the ports tree. I use my desktop
computer mainly for work (programming, reading, writing, researching information
on the internet) and some entertainment mostly provided through the web browser
(reading, videos).

I generally use mid-range commodity hardware with on-board graphics, so hardware
compatibility should not be an issue. My desktop computer is a small-form Dell
OptiPlex 7040 from 2016 with an Intel Core i5 CPU. I replaced the original 128
TB SSD with a 500 GB model last year, and upgraded the original 8 GB of memory
with a ridiculous amount of 24 GB. (Some RAM bars just happened to lay around
here…) The computer has a WiFi card, of course, but since my router is just next
to my desk, I rather use a stable ethernet connection.

I already tried out OpenBSD once on that computer, and didn't have any issues
getting it to run. So FreeBSD having access to the same code base under a
compatible license is likely to suppport this hardware as well. Let's just try
it out!

# Preparations

FreeBSD supports multiple versions at any given point in time. At the time of
this writing, 12.1 and 11.4 are the current versions intended for production.
Let's pick the most recent version 12.1. The [download
page](https://download.freebsd.org/ftp/releases/amd64/amd64/ISO-IMAGES/12.1/)
for the `amd64` architecture offers various options. The compressed
`mini-memstick` archive weighs the least and provides everything that is needed
for an installation on a computer with internet connection. I download it to my
laptop running Arch Linux, and then verify the checksum:

    $ wget https://download.freebsd.org/ftp/releases/amd64/amd64\
    /ISO-IMAGES/12.1/FreeBSD-12.1-RELEASE-amd64-mini-memstick.img.xz
    $ wget https://download.freebsd.org/ftp/releases/amd64/amd64/\
    ISO-IMAGES/12.1/CHECKSUM.SHA512-FreeBSD-12.1-RELEASE-amd64
    $ sha512sum -c CHECKSUM.SHA512-FreeBSD-12.1-RELEASE-amd64 --ignore-missing
    FreeBSD-12.1-RELEASE-amd64-mini-memstick.img.xz: OK

The archive (389 MBs) needs to be unpacked and is then copied to a USB dongle
(`/dev/sda`):

    $ unxz FreeBSD-12.1-RELEASE-amd64-mini-memstick.img.xz
    # dd if=FreeBSD-12.1-RELEASE-amd64-mini-memstick.img of=/dev/sda bs=1M
    $ sync

# Initial Setup

The BIOS is setup to use UEFI rather than legacy boot. I plug in the USB dongle
and start the FreeBSD installer. These are the settings I use during setup:

- Keymap: Swiss-German (`ch.kdb`)
- Hostname: `optiplex` (I'm not very imaginative when it comes to naming
  things.)
- Components: just `lib32`, `ports`, and `src`
- Network: interface `em0` with DHCP and IPv4
- Mirror: Main Site
- Partitioning: Auto (UFS, I'm going to learn about ZFS later) on the entire
  disk `ada0` using GPT and the following partitions (device, space, type,
  label, mount point):
    - `ada0p1`: 200 MB `efi` boot (no mount point)
    - `ada0p2`: 24 GB `freebsd-swap` swap0 (no mount point, size of physical memory)
    - `ada0p3`: 16 GB `freebsd-ufs` root `/`
    - `ada0p4`: 4 GB `freebsd-ufs` temp `/tmp`
    - `ada0p5`: 4 GB `freebsd-ufs` var `/var`
    - `ada0p6`: 32 GB `freebsd-ufs` usr `/usr`
    - `ada0p7`: 386 GB `freebsd-ufs` home `/home` (remainder of the space)
- Root password: I won't tell you, but a strong one!
- CMOS clock: UTC
- Time Zone: Europe/Switzerland (`CEST`)
- Services: `sshd`, `moused`, `ntpd`, `powerd`, and `dumpdev`
- Security Hardening Options: everything
- User: `patrick` with additional group `wheel` (to become root), the `tcsh`
  shell, a strong password, and, otherwise, suggested settings

It can be argued if the chosen partition sizes are reasonable. However, it is
always a good idea to use separate `/tmp` and `/var` partitions to make sure
that no process can fill up the entire disk. (Using a separate `/usr` partition
is an issue on Linux nowadays, since the widely used init system systemd
requires access to `/usr`. On FreeBSD, it is still possible to do so without any
issues.)

Make sure to use `efi` as the type for the boot partition, not `freebsd-boot` as
suggested in _Absolute FreeBSD_ (3rd Edition on page 36).

# First Boot, First Issues

After the installation, I choose to shutdown the system. I unplug my USB dongle
as soon as the screen turns black.

Before the first boot, I have to change my boot options in the BIOS so that the
computer boots from the SSD on which FreeBSD was just installed.

The system boots and even shows my mouse on the terminal! The network is up and
running. However, there is a message warning me that the leapsecond file is
expired. The
[solution](https://forums.FreeBSD.org/threads/leapseconds-file-expired.56645/post-322290) suggested in the FreeBSD Forum

    # service ntpd onefetch

fails with a certificate verification error. A [bug
report](https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=230017) suggest to
install the package `ca_root_nss`:

    # pkg install ca_root_nss

Which not only installs the package management software, but also solves the
issue above: The warning concerning the leapsecond file doesn't appear after the
next boot. Now that the basic system is up and running, let's tackle the GUI!

# Installing the GUI

Since _Absolute FreeBSD_ doesn't cover graphical user interfaces, I have to
resort to the handbook. In [Chapter
5.3](https://www.freebsd.org/doc/handbook/x-install.html) it says that the
easiest way to setup the X Window System is to install the `xorg` package. Since
I prefer a minimalistic setup, I opt for the `x11/xorg-minimal` package instead:

    # pkg install x11/xorg-minimal

This package depends on Python 3.7, Perl 5, and Wayland, among others, and
weighs roughly 1 GB, which is not exactly minimalistic in my opinion. On the
other hand, it is notable that the base setup works without Perl or Python.
(Which _is_ minimalistic.)

## Compiling `dwm`

Since I like to keep my `dwm` version up to date, I fetch the sources using
`git`, which first needs to be installed:

    # pkg install git
    # git clone https://git.suckless.org/dwm

A first naive compilation attempt fails:

    # cd dwm
    # make
    drw.c:5:10: fatal error: 'X11/Xlib.h' file not found
    #include &lt;X11/Xlib.h&gt;

The `config.mk` file expects the header files to be located under
`/usr/X11R6/include`. However, FreeBSD has those files stored under a different
location:

    # find / -type f -name Xlib.h
    /usr/local/include/X11/Xlib.h

So in `config.mk`, the lines

    X11INC = /usr/X11R6/include
    X11LIB = /usr/X11R6/lib

need to be replaced with

    X11INC = /usr/local/include
    X11LIB = /usr/local/lib

The next compilation fails with another error (different error message, yay!):

    # make
    drw.c:6:10: fatal error: 'X11/Xft/Xft.h' file not found

That's the price I have to pay for minimalism, I guess. Executing `pkg search
Xft` reveals the package `libXft`, which I install:

    # pkg install libXft

This shows to be a good idea, because now I'm getting a different error message:

    # make
    Xft.h:39:10: fatal error: 'ft2build.h' file not found

It turns out that the file is on the system, but cannot be found:

    # find / -type f -name ft2build.h
    /usr/local/include/freetype2/ft2build.h

Again, the `local` path segment is missing in `config.mk`:

    FREETYPEINC = /usr/include/freetype2

Which is changed as follows:

    FREETYPEINC = /usr/local/include/freetype2

Retry, fresh error again:

    # make
    dwm.c:40:10: fatal error: 'X11/extensions/Xinerama.h' file not found

The `config.mk` contains the following section:

    # Xinerama, comment if you don't want it
    XINERAMALIBS  = -lXinerama
    XINERAMAFLAGS = -DXINERAMA

So what is _Xinerama_, after all? According to
[Wikipedia](https://en.wikipedia.org/wiki/Xinerama):

&gt; Xinerama is an extension to the X Window System that enables X
&gt; applications and window managers to use two or more physical displays as
&gt; one large virtual display. 

Since I have only one screen, I can do without Xinerama, so I comment out those
lines:

    # Xinerama, comment if you don't want it
    # XINERAMALIBS  = -lXinerama
    # XINERAMAFLAGS = -DXINERAMA

Now `dwm` compiles, and I can install it:

    # make dwm
    # make install

## Starting Xorg with `dwm`

I switch to my personal account and create the file `/home/patrick/.xinitrc`
with the following content:

    exec dwm

Now I run `startx`, which unfortunately fails:

    Fatal server error:
    (EE) no screens found(EE)

The error log `/var/log/Xorg.0.log` does not offer any additional information
that seems helpful to me. It turns out that `/etc/X11` is empty. [Section
5.4](https://www.freebsd.org/doc/handbook/x-config.html) of the handbook is
about Xorg configuration. I create a minimalistic configuration for my graphics
card (onboard Intel GPU) in `/etc/X11/xorg.conf`:

    Section &quot;Device&quot;
        Identifier &quot;Card0&quot;
        Driver     &quot;intel&quot;
    EndSection

I also need to install the display driver with the matching kernel module,
because my choice of `xorg-minimal` from before.

    # pkg install xf86-video-intel drm-kmod

(Note that «drm» doesn't stand for «digital rights management» in this context,
but for «direct rendering modules».) The kernel module can be activated on
startup by adding it to the `rc.conf` as follows:

    # echo 'lkd_list=&quot;/boot/modules/i915kms.ko&quot;' &gt;&gt; /etc/rc.conf

After a restart, the console is shown in a much higher resolution. However,
`startx` now complains about a missing font. Let's install the `xorg-fonts` meta
package, which should provide a monospace font needed for `dwm`:

    # pkg install xorg-fonts

Now, finally, `dwm` works! Since `startx` is long to type, I define the alias
`x` for it in `~/.cshrc`:

    alias x startx

And start `dwm`:

    $ x

## Configure `dwm`

By default, `dwm` uses the Alt key as the modifier key (`MODKEY`). I prefer to
use the «Windows» or «Super» Key, for it has no other purpose on my system.
(`Alt` is useful for some emacs-style readline commands.) To do this, the
`MODKEY` variable has to be changed in `config.h` as follows:

    #define MODKEY Mod4Mask

The default rules make Firefox appear on the last tag, and Gimp to be used with
floating layout, which makes no sense with more recent versions of Gimp. Let's
just undefine those rules:

    static const Rule rules[] = {
        {NULL, NULL, NULL, 0, 0, -1},
    };

I also like my windows to be split evenly:

    static const float mact = 0.50;

As a terminal, let's use `qterminal` instead of `st`, for the latter does not
support scrollback buffers:

    static const char *termcmd[] = {&quot;qterminal&quot;, NULL};

`qterminal` and `dmenu` need to be installed:

    # pkg install qterminal dmenu

## Status Line

`dwm` can display status information using the `xsetroot` command. The text to
be displayed is computed in a background task that can be defined in `.xinitrc`.
On laptops, I usually print the battery status. On desktops, the current date
and time suffices. Here's the `.xinitrc` that displays this information
(surrounded by spaces) in five second intervals:

    while true
    do
        xsetroot -name &quot; $(date +'%Y-%m-%d %H:%M') &quot;
    done &amp;
    setxkbmap ch
    exec dwm

The keymap is also set to the `ch` (i.e. Swiss German) variant just before
executing `dwm`. The `xsetroot` and `setxkbmap` utilities need to be installed
for this:

    # pkg install xsetroot setxkbmap

## Volume Control

In order to test audio, let's download the Free Software Song:

    $ curl https://www.gnu.org/music/free-software-song.ogg &gt; fss.ogg

I prefer `mplayer`, which needs to be installed:

    # pkg install mplayer

Make sure to include `/usr/local/bin` in your `$PATH` variable in order to run
`mplayer` without further path specification (`.cshrc`):

    export PATH=&quot;$PATH:/usr/local/bin&quot;

Playing the song as follows works if I plug in a headphone into one of the front
audio sockets:

    $ mplayer fss.ogg

The devices are listed in `/dev/sndstat` and switched by setting the respective
device number:

    # sysctl hw.snd.dfault_unit=1

The default volume is set to 85, which is quite loud for Richard Stallman's
singing voice. The volume can be changed relatively or absolutely using the
`mixer` command:

    $ mixer vol -10
    Setting the mixer from 85:85 to 75:75
    $ mixer vol 50
    Setting the mixer from 75:75 to 50:50

I don't always want to type that command, but rather use the volume keys on my
keyboard. So let's add a couple of commands to the `dwm` config (`config.h`,
just before the `keys[]` section):

    static const char *upvol[] = {&quot;mixer&quot;, &quot;vol&quot;, &quot;+5&quot;});
    static const char *downvol[] = {&quot;mixer&quot;, &quot;vol&quot;, &quot;-5&quot;});

For the key mapping, I first need to figure out the key codes for my volume
keys, which can be done using `xev`:

    # pkg install xev
    $ xev &gt; xev.out

Just press the volume up and volume up button in that order. Then close the
`xev` window and inspect `xev.out`.

**Unfortunately, the volume keys do not trigger an event.** There must be
something wrong with the keyboard configuration. So let's use Page Up and Page
Down to increase and decrese the volume (`keys[]` array in `config.h`):

    static Key keys[] = {
        // lines omitted
        { MODKEY, XK_Page_Up,   spawn, {.v = upvol}   },
        { MODKEY, XK_Page_Down, spawn, {.v = downvol} },
    };

Then simply re-compile, re-install, and re-start `dwm`:

    # make install
    $ x

Now Richard Stallman can be made to sing louder or quieter by pressing
Super+PgUp and Super+PgDown, respectively, _which is goood, hackers, which is,
goo-oo-ood!_

# Conclusion

Setting up the FreeBSD base system was rather easy. I made the mistake of using
`freebsd-boot` and not `efi` as the partition type for the boot partition, which
seems to be a mistake in the otherwise amazing book _Absolute FreeBSD_.

Installing the `x11/xorg-minimal` package instead of the full `xorg` package
caused some additional trouble, but helped me to better understand which
components are actually required to compile and run `dwm`. Instead of just
installing Xinerama, as I always did on Linux, the extra pain of libraries not
found made me investigate if I actually need that component. It turned out, I
don't.

I also needed to install the graphics driver and according kernel module
manually. Doing so, I realized that FreeBSD offers a nice graphical console,
which is a good fit for a `tmux` environment I use once in a while to work
absolutely focused.

Having audio running (almost) out of the box was a positive surprise. The
`mixer` interface is very simplistic. Switching audio devices, however, requires
an option to be changed using `sysctl`. This calls for some additional `dwm`
shortcuts!

My keyboard (a Cherry board with MX Brown switches) doesn't work properly out of
the box. I read about `uhidd`, which could be used to fix my issue with the
volume keys. But for the moment, I have a working setup.

I'll come back to the open issues in a later article. But first, I'd like to
work with my new FreeBSD desktop as much as possible to gain more experience.
</content>
    </entry>
    <entry>
        <title>«Four in a Row» in Haskell (Part II)</title>
        <link href="https://paedubucher.ch/articles/2020-08-05-four-in-a-row-in-haskell-part-ii.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-08-05-four-in-a-row-in-haskell-part-ii.html</id>
        <updated>2020-08-05T23:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
In my [last
article](https://paedubucher.ch/articles/2020-08-03-four-in-a-row-in-haskell-part-i.html),
I outlined the purpose of a _stock program_: a non-trivial coding exercise to
be done in every new programming language somebody is learning. I also stated
that «Four in a Row» is becoming my personal stock program, and that I'd like to
implement it in Haskell.

The main challenge in Haskell is the functional programming paradigm.
Immutability is the main difference between an implementation of «Four in a
Row» in a functional programming language compared to rather structured
programming languages such as C or Python. The object-oriented aspect of an
implementation in Python makes hardly any difference, for OOP equally allows for
mutable an immutable programming beneath the surface. (In introductory courses
on OOP, hidden mutability is rather praised as a virtue than frowned upon; the
disadvantages of mutability are only taught in advanced courses by showing the
advantages of constructs like immutable classes. Learn and unlearn, but I'm
digressing…)

A later re-implementation of my stock program in Python might profit from the
experiences made in Haskell. Structured programming also allows for
immutability, and list comprehensions allow for compact code to produce new
state based on older state, without modifying existing state. (This
re-implementation could be subject matter for a fourth article, but let's not
get ahead of ourselves.)

In this article, I'm going to show how the board logic for the game «Four in a
Row» can be implemented in Haskell.

# Let There Be Code

As analyzed in my previous article, the board logic consists of five building blocks:

1. Create an empty grid with given dimensions.
2. Validate if a move (i.e. the choice of a column) is allowed for a given board.
3. Set a player's stone in the right place on the grid based on the choice of a column.
4. Detect if a player has won the game by checking if four of the player's
   stones lay in a horizontal, vertical, or diagonal line.
5. Format the grid as a string in order to display it on the command line.

The last building block, formatting, won't be covered in this article. I first
have to learn more about strings, formatting, and IO in Haskell, but I don't
like to wait to cover the other parts, which I'm already capable of
implementing with my current knowledge.

## Type Glossary

Before implementing the actual logic, let's define a couple of type aliases:

    type Grid = [Row]
    type Row = [Int]
    type Col = [Int]
    type Stone = Int

A grid (type `Grid`) is a list of rows. A row (type `Row`) itself is a list of
integers. As discussed in my previous article, 0 is going to be used for empty
fields. The fields occupied by player one and two shall be represented by the
numbers 1 and 2, respectively.

Just like a row, a column (type `Col`) is a list of integers. It is an
alternative way to express the relationships between individual fields. The
`Grid`, however, uses the `Row` type as its building blocks.

A `Stone` is an integer, too. It represents a player's number for fields
occupied by his or her stones.

Those types won't add powerful abstractions to the program, but make the
signature of certain functions a bit clearer. (It's also possible to limit the
scope of the types declared to certain values, but let's focus on the program
logic instead.)

## Creating a Grid

The function `new_grid` accepts two integer parameters (number of rows and
columns), and produces a grid of those dimensions:

    new_grid :: Int -&gt; Int -&gt; Grid
    new_grid r c = [new_row c | _ &lt;- [1..r]]

A list comprehension is used to build up the grid as a list of `r` rows. The
row itself is created by a function `new_row`:

    new_row :: Int -&gt; Row
    new_row c = [0 | _ &lt;- [1..c]]

Again, a list comprehension is used to build a single row consisting of `c`
elements: one per column.

The `new_grid` function can be used as follows (`&gt;` indicates the REPL, the
output has been wrapped for better readability):

    &gt; new_grid 6 7
    [[0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0]]

## Validating a Move

A move solely consists of a column index. Let's assume a 6x7 grid (6 rows, 7
columns) if nothing else is stated. A valid move must be in the range of 0
(leftmost column) to 6 (inclusive, rightmost column).

For a move to be valid, the column must have an empty field, i.e. it must
contain the value 0. Since the columns are filled up from the bottom, a column
is not full if its the top-most field is equal to 0. So this validation seems
trivial.

However, in order to deal with _columns_ rather than _rows_ (remember, the grid
is defined in terms of rows, not the other way around), we first need a way to
gather the fields of a column. The function `get_column` expects a grid and a
column index and returns the fields belonging to that particular column:

    get_column :: Grid -&gt; Int -&gt; Col
    get_column g c = [row !! c | row &lt;- g]

A list comprehension is used to select the element at index `c` in every grid
row using the index operator (`!!`).

The function `is_valid_move` simply extracts the column chosen by the player
and checks its topmost field to be empty (equals 0, that is):

    is_valid_move :: Grid -&gt; Int -&gt; Bool
    is_valid_move g c = (get_column g c) !! 0 == 0

(Notice that no boundary checks are implemented throughout the program, unless
absolutely necessary for getting the logic right.)

This function can be used as follows:

    &gt; g = new_grid 6 7
    &gt; is_valid_move g 0
    True

## Setting a Stone

The first two building blocks were easy to write without modifying state.
Performing a move on the grid by setting a stone into a certain column,
however, is a step that requires a modification of some sort. The solution is
to not mutate the given grid, but to produce a new grid based on the given grid
by accounting for a player's move.

The function `apply_move` expects a grid, a column (chosen by the player and
validated using `is_valid_move`), and the player's number (to set the right
value in the new grid):

    apply_move :: Grid -&gt; Int -&gt; Int -&gt; Grid

Because only a column is given, the row coordinate has to be figured out. Since
stones played are falling down the grid in the physical version of the game,
the bottom-most free field of a column has to be found:

    bottom_most :: Grid -&gt; Int -&gt; Int -&gt; Int
    bottom_most g v c = length (takeWhile (\x -&gt; x == v) col) - 1
                        where col = get_column g c

The lowest free position is found by extracting a subsequent list of a given
value `v`, which can be handed in as an argument. (The value 0 has to be used
for this particular use case by the caller.) The built-in function `takeWhile`
is used to extract a list based on a lambda expression: Elements are taken from
the column as long as the lambda expression holds true. The bottom-most position
of a column with the given value `v` is simply the length of the extracted sub
list minus one (indexes are zero-based). Again, the `get_column` function is
used to get access to the fields of a particular column. 

Now `apply_move` can be implemented as follows:

    apply_move g c p = replace_value g r c p
                       where r = bottom_most g 0 c

Another function is needed: `replace_value`, which creates a new grid based on
the existing grid `g`, by setting the player's stone value `p` to the coordinate
`(r,c)`. (The row coordinate is figured out using `bottom_most`, as shown
above.)

The function `replace_move` is implemented as follows:

    replace_value :: Grid -&gt; Int -&gt; Int -&gt; Stone -&gt; Grid
    replace_value g r c p = take r g ++ [new_row] ++ drop (r + 1) g
                            where new_row = replace_row_value (g !! r) c p

Given the row index `r`, the first `r` rows are taken. (This excludes the row
to be transformed, because the index is zero-based.) The row at index `r` is
computed as `new_row` in a further step. The remaining rows are extracted from
the existing grid by dropping the first `r + 1` rows from it. Those three
components are concatenated to a new grid using the `++` operator.

The `new_row` looks like the old row at index `r`, expect that a single value
at index `c` (the column) has to be replaced with the player's value `v`. The
function `replace_row_value` performs this transformation:

    replace_row_value :: Row -&gt; Int -&gt; Stone -&gt; Row
    replace_row_value r c p = take c r ++ [p] ++ drop (c+1) r

The same logic using `take` and `drop` can be implemented for the column's
fields like for the grid's rows before. The empty field at column index `c` can
simply be replaced by a list solely consisting of the player's stone value `v`.
List concatenation is used again to produce the tranformed column.

A move can be applied as follows:

    &gt; g = new_grid 6 7
    &gt; g1 = apply_move g 3 1
    &gt; g1
    [[0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,1,0,0,0]]

    &gt; g2 = apply_move g1 4 2
    &gt; g2
    [[0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,0,0,0,0],
     [0,0,0,1,2,0,0]]

`apply_move` could also be invoking `is_valid_move` for validation. But this
task should be left for the client to be implemented later on.

## Detecting a Win

Figuring out whether or not a player's most recent move leads to a win is the
hardest part of this program, no matter what implementation language is used.
(However, I didn't try Prolog _yet_ for this.) Let's analyze the problem.

First, what do we know? The player with a number (1 or 2) just picked a column
(between 0 and 5 in our 6x7 grid). A stone was set in the bottom-most empty
field of that column. The actual row where the stone landed in is unknown.
However, this information can be found out: it is the top-most row of the chosen
column holding the player's stone value. All the fields above must be empty.

Second, what do we need to find out? Starting from the coordinates (given
column, row figured out as described above), there are three possibilities to
build a row of four values: horizontal, vertical, and diagonal lines. A
horizontal line is a row, and a vertical row is a column. Diagonal lines can
occur in two directions: ascending or descending. So we actually need to account
for four kinds of rows, which need to be extracted from the row/column
coordinates.

Third, once the horizontal, the vertical, and the two diagonal lines going
through the player's stone most recently set are established, a simple check can
be done: Does the line, which can be represented as a list, contain a list of
four of the player's stones? If that's the case, the player just won the game.

Let's implement that algorithm in a top-down manner!

The function `is_win` expects a grid, a column, and a player's stone value, and
returns a boolean value indicating if the player just won the game:

    is_win :: Grid -&gt; Int -&gt; Stone -&gt; Bool
    is_win g c p = horizontal_win g row p ||
                   vertical_win g c p ||
                   diagonal_win g row c p
                   where row = top_most g p c

Three predicate functions `horizontal_win`, `vertical_win`, and `diagonal_win`
handle the three different shapes of winning rows. To check for a vertical win,
the row is irrelevant. For the other wins, the row where the player's stone just
landed in is figured out using the `top_most` function:

    top_most :: Grid -&gt; Stone -&gt; Int -&gt; Int
    top_most g v c = length (takeWhile (\x -&gt; x /= v) col)
                     where col = get_column g c

This function expects a grid, a player's stone value, a column, and returns the
top-most row containing the player's stone. Going through the column from top to
bottom, values are read into a list as long as they are not equal to the
player's stone value. The length of that list is the row coordinate of the
player's top-most stone in that column. Again, the column is extracted using the
`get_column` function explained further above.

### Vertical and Horizontal Win

A vertical and horizontal winning row can be detected in the same manner. The
only difference is that the former works on columns, and the latter on rows:

    horizontal_win :: Grid -&gt; Int -&gt; Stone -&gt; Bool
    horizontal_win g r p = contained fiar (g !! r)
                           where fiar = [p | _ &lt;- [1..4]]

    vertical_win :: Grid -&gt; Int -&gt; Stone -&gt; Bool
    vertical_win g c p = contained fiar (get_column g c)
                         where fiar = [p | _ &lt;- [1..4]]

In both cases, a grid, an index (row or column, respectively), and a player's
stone value is expected. The boolean return value indicates whether or not the
row or column contains a sub-list consisting of four of the player's stone
values: `fiar`, which is built using a list comprehension.

For the horizontal win, the row can be directly accessed from the grid using the
row index (`g !! r`). For the vertical win, the `get_column` function is used
once again.

The function `contained` is the tricky part. This function checks whether or not
a smaller list (first argument) is part of a larger list (second argument). A
possible implementation looks as follows:

    contained :: Eq a =&gt; [a] -&gt; [a] -&gt; Bool
    contained [] []                     = True
    contained [] ys                     = True
    contained xs []                     = False
    contained (x:xs) (y:ys) | x == y    = and [x == y | (x,y) &lt;- zip xs ys]
                                          &amp;&amp; length xs &lt;= length ys
                                          || contained (x:xs) ys
                            | otherwise = contained (x:xs) ys

The lists processed can be of any type that supports the comparison operator
(`Eq a`). A boolean value is returned indicating whether or not the first list
is contained in the second list. The function is implemented using pattern
matching, which covers the following cases:

1. An empty list is contained in another empty list (first base case).
2. An empty list is contained in any non-empty list (second base case).
3. A non-empty list is not contained in an empty list (negative base case).
4. A non-emtpy list is _possibly_ contained in another non-empty list (complex
   case).

The «possibly» in the fourth case can be resolved as follows: If the first
elements of the two lists do match, the remainders of the two lists need to be
checked for a match. A list comprehension zipping those tails together and
comparing the corresponding elements creates a list of booleans indicating
matches. If all those booleans are `True`, the first list must be contained in
the second list, _if the second list is at least as long as the first list_.
(Notice that the `zip` function only picks values until the shorter of the two
zipped lists is exhausted. The length check ensures that the comparison of the
lists does not end prematurely.)

The `otherwise` case is processed when the two list's heads do not match. In
this case, the `contained` function is invoked again with the full first list
and the second's list tail: It shall be checked whether or not the first list is
contained in the second's list tail.

### Diagonal Win

Detecting a diagonal win works in the same manner as detecting a horizontal or
vertical win. However, there are two subtle details that make the implementation
more complicated:

First, there are _two_ kinds of diagonal lines: ascending and descending. This
can be handled by implementing two different functions.

Second, extracting a diagonal line as a list from the two-dimensional grid is
much more complicated than extracting a horizontal line (row) or a vertical line
(column).

Let's start with the `diagonal_win` function, which accounts for both winning
rows in ascending or descending order:

    diagonal_win :: Grid -&gt; Int -&gt; Int -&gt; Stone -&gt; Bool
    diagonal_win g r c p = contained fiar (diag_asc g r c) ||
                           contained fiar (diag_desc g r c)
                           where fiar = [p | _ &lt;- [1..4]]

The function expects a grid, both row and column indication, and the player's
stone value. As always, a boolean value indicating a win is returned. A win is
detected, if the list of four player's stone values is contained in either the
ascending or the descending diagonal line.

Those lines are extracted from the grid using the `diag_asc` and `diag_desc`
functions, respectively. The two functions look quite similar, but have subtle
differences in the way they process the grid:

- An _ascending_ row starts at the bottom of the grid, i.e. with the highest row
  index. It starts at the left, i.e. with the lowest column index.
- A _descending_ row starts at the top of the grid, i.e. with the lowest row
  index. It also starts at the left, and, thus, with the lowest column index.

The function `diag_asc` expects a grid and both row and column indices. It
returns the ascending diagonal row containing that coordinate:

    diag_asc :: Grid -&gt; Int -&gt; Int -&gt; [Int]
    diag_asc g r c = [g !! i !! j | (i,j) &lt;- zip rows cols]
                     where
                       nrows   = length g
                       ncols   = length (g !! 0)
                       offset  = max (min (nrows - r - 1) (ncols - c - 1)) 0
                       max_row = r + offset
                       min_col = c - offset
                       rows    = reverse [0..max_row]
                       cols    = [min_col..ncols-1]

The function is implemented using a list comprehension. The variable `i` is the
row index, `j` the column index. Those indices are obtained by zipping a list of
row indices (`rows`) with a list of column indices (`cols`). The starting and
end point of those lists are the tricky part.

Consider this grid, in which `-` stands for an empty field, and the upper-case
`F` for the field played most recently (with the `r` and `c` arguments as
indices). All the fields indicated with a lower-case `f` are to be extracted for
the ascending diagonal holding the upper-case `F`:

        !
    0 1 2 3 4 5 6
    - - - - - - f 0
    - - - - - f - 1
    - - - - f - - 2
    - - - f - - - 3
    - - F - - - - 4 !
    - f - - - - - 5

The row and column indices of `F` are given as 4 and 2. The starting point at
the bottom-left can be figured out by shifting the coordinates by an _offset_.
This offset is the smaller value of the following two differences:

- `rows - r - 1`: the number of rows minus the row index (minus one to account
  for the zero-based row index)
- `cols - c - 1`: the number of columns minus the column index (minus one;
  zero-based index again)

The offset is set to 0, if either difference becomes negative (boarder
clipping). The offset is calculated as follows:

    offset = max (min (nrows - r - 1) (ncols - c - 1)) 0
    offset = max (min (6 - 4 - 1) (7 - 2 - 1)) 0
    offset = max (min 1 4) 0
    offset = max 1 0
    offset = 1

And the starting points `max_row`/`min_col` (bottom left) are calculated based
on the given indices of `F` as follows:

    max_row = r + offset
    max_row = 4 + 1
    max_row = 5

    min_col = c - offset
    min_col = 2 - 1
    min_col = 1

The diagonal line can be drawn up to the row index 0 and the column index 6.
Here, it is possible to always use the maximum value, because the `zip` function
will stop picking values once the shorter list is exhausted.

The number of rows and columns can simply be figured out using the `length`
function applied on the grid as a whole and on a single row thereof:

    nrows = length g
    ncols = length (g !! 0)

Notice that in order to create a list containing the _falling_ values from
`max_row` down to 0 (`rows`), a rising list from 0 to `max_row` has to be
created and reversed:

    &gt; reverse [0..max_row]
    [0,1,2,3,4,5]

The other way around, an empty list would be created:

    &gt; [max_row..0]
    []

The somewhat easier to understand function `diag_desc` is simply pasted here
without any further comments.  Figuring out how it works is left to the reader.
The extensive comments above on `diag_asc` certainly help for this purpose:

    diag_desc :: Grid -&gt; Int -&gt; Int -&gt; [Int]
    diag_desc g r c = [g !! i !! j | (i,j) &lt;- zip rows cols]
                      where
                        offset  = min r c
                        min_row = r - offset
                        min_col = c - offset
                        nrows   = length g
                        ncols   = length (g !! 0)
                        rows    = [min_row..nrows-1]
                        cols    = [min_col..ncols-1]

# Conclusion

The complete board logic required to implement a basic «Four in a Row» game has
been implemented in Haskell. The whole code described, plus some additional
attempts to format the grid as a string, can be found on
[GitHub](https://github.com/patrickbucher/programming-in-haskell/blob/master/four-in-a-row/Board.hs).

The linked code also defines a module `Board` which exports the public interface
of the board consisting of the four building blocks discussed in this article
and its predecessor. The file
[BoardTest.hs](https://github.com/patrickbucher/programming-in-haskell/blob/master/four-in-a-row/BoardTest.hs)
defines a couple of unit tests written in HUnit for basic verification of the
logic.

The actual board logic requires a little less than 100 SLOC. Comparable
implementations I've written in Python and C only take up slightly more lines. I
could have made some functions _shorter_, but probably not _clearer_ with my
limited knowledge of Haskell.

The `contained` function, for example, looks a bit bulky, but actually contains
very little logic. It is possible that the negative base case could be
eradicated, because a length check is already performed in the complex case.
However, I rather have a clear statement of the base cases than saving an easy
to understand line of code.

I might revisit this code and improve it as my knowledge of Haskell improves.
But the next step in my journey is to implement an interactive game based on
this board, which will be the subject of an article to be published in weeks or
maybe months.
</content>
    </entry>
    <entry>
        <title>«Four in a Row» in Haskell (Part I)</title>
        <link href="https://paedubucher.ch/articles/2020-08-03-four-in-a-row-in-haskell-part-i.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-08-03-four-in-a-row-in-haskell-part-i.html</id>
        <updated>2020-08-03T12:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
In a [recent interview](https://youtu.be/O9upVbGSBFo?t=3741), Brian W. Kernighan
said that he always re-implements the same program when he's learning a new
programming language. In his case, it's a programm to process a text file
containing a variable number of lines. In this task, his programming language
AWK (Kernighan is the «K» in «AWK») shines, for it was designed for that kind of
a task.

Such a _stock program_ allows to evaluate a programming language from a certain
perspective. Different programs offer different perspectives. I personally
didn't have such a stock program yet, but there is at least one program I have
already implemented in multiple programming languages: the board game _Four in a
Row_.

# Four in a Row: My Stock Program

This game is played by two players, usually on a 7x6 grid (seven columns, six
rows). The grid is setup to be perpendicular to the table, so that the stones
fall to the lowest free field of the chosen column. The players take turns
setting their stones (red for one player, yellow for the other one). The player
that first can set four of stones into a horizontal, vertical, or diagonal row
wins the game.

I first implemented this game as a program towards the end of my first year as
an apprentice. The task was an optional assignment in an introductory
programming class. C was used as the implementation language. A more recent
re-implementation of that program is available on
[GitHub](https://github.com/patrickbucher/prog/blob/master/vier_gewinnt/vier_gewinnt.c).
The hardest part was to get the winning detection right, especially for the
diagonal rows. Since the grid was implemented as a two-dimensional array,
diagonals clipping the edge would erroneously also be detected as a winning row.
Some additional checks for index boundaries fixed the issue.

16 years later, my apprenticeship already was far in the past. I was studying
computer science in my eight and last term. For a _Game Design_ class, I had to
write a case study on improving an existing game. I picked _Four in a Row_ and
extended it with a couple of new game mechanics. The case study, written in
German, and the source code, can be found on
[GitHub](https://github.com/patrickbucher/v13r93w1nn7), too. This time, I used
Python as the implementation language. The [NumPy](https://numpy.org/) library
made this task very comfortable, and I was able to implement the board logic
with rather few lines of Python code. The unit tests, implemented using
[PyTest](https://docs.pytest.org/en/stable/), took up far more lines than the
actual code.

Both versions were implemented for the command line. However, the latter
version was implemented in a way that would also support graphical frontends.

## Building Blocks

Having implemented the same program with much more programming experience and
using a different programming language, the resulting code looked quite
different. However, I was able to detect some common patterns.

On a very high level, there are two parts for such a program: First, the _board
logic_ that deals with the grid, its manipulations and validations (Is a row not
full yet?  What is the bottom-most empty row in a given column? Are four stones
of the same color in a row?). Second, the _game logic_, which consists of a big
loop that lets the players take turns setting their stones, prints the grid, and
ends the game upon a win or draw.

The board logic can be taken further apart into the following components:

1. **Creating an Empty Grid**: At the beginning of a game, an empty grid with
   given dimensions has to be created. (The physical game is played on a 7x6
   grid, but a computer game can offer additional flexibility with the number of
   rows and columns given as arguments.)
2. **Validating a Move**: As soon as all fields of a column are filled, the
   column must no longer be chosen by players. A function is needed that checks
   which columns still have at least one empty field.
3. **Setting a Stone**: If a stone is to be set into a non-full column, the
   bottom-most empty row of that column has to be figured out. Then, the field
   is modified by setting the player's stone into that position.
4. **Detecting a Win**: After every move, it has to be checked whether or not
   the grid contains four stones of the same color laying in the same
   horizontal, vertical, or diagional row, without any gaps in between. If the
   detection gets to know which player did the last move, and into what
   coordinates that stone was put, the algorithm has to do less work, as opposed
   to an approach where the whole grid is evaluated for both players. (For the
   case-study, I had to use the latter approach, for one of the additional game
   mechanics allowed to flip the grid, which required a full evaluation of the
   whole grid afterwards.)
5. **Formatting the Grid**: This part could also be implemented in the game
   logic.  However, offering the capability to print the current grid from the
   board component (be it a module or a class) in a nicely formatted way is a
   good design decision in terms of cohesion. This function can be made very
   flexible by accepting formatting parameters, such as the characters to be
   used to display fields that are empty, or contain a stone of either player.

A function to format the current grid makes an important separation between the
inner state of the grid and its textual representation on the command line. It
is a good idea to represent the state of the fields as _numbers_ internally,
but to use _characters_ in order to display them nicely on the command line.
Internally, `0` can used for empty fields. For fields holding a stone of player
one or two, the values `1` and `2`, respectively, can be used. The empty field
can be displayed using a whitespace character, an underscore, or a dash. The
stones of the players can be easily distinguished when using `x` and `o` for
their output.

# Towards Haskell

The programming language _Haskell_, which has been mentioned in this article's
title, but not in the text ever since, shall be used to create an additional
implementation of the _Four in a Row_ game. But why Haskell?

First, I'm currently learning Haskell. It turns out that writing useful programs
in Haskell is not that easy, because advanced concepts like Monads have to be
understood in order to perform input/output operations. I'm working through the
rather dense book [Programming in Haskell (Second
Edition)](https://www.cs.nott.ac.uk/~pszgmh/pih.html) (by Graham Hutton) at the
moment, and I've almost finished the first part. The knowledge acquired from
those first nine chapters allows me to implement the board logic. The
interactive part then has to wait until I (nearly) finished the book.

Second, I'm interested in functional programming. I consider Haskell as a
stepping stone into that programming paradigm. I have some minor experience in
Prolog, and I'd like to learn Erlang later on. Knowledge about functional
programming also helps when programming in Python and JavaScript, which also
support features like lambda expressions, higher-order functions, and, in case
of Python, list comprehensions.

Implementing _Four in a Row_ in Haskell gives me a couple of challenges.
Unlike an implementation in C or Python, the grid must not be modified during
gameplay. A new grid, representing the fresh state, has to be build up based on
the previous state and the player's action, instead. I also need to figure out
how to detect a winning row in a declarative way, i.e. without loops and
counter variables. The input/output of the actual game logic will probably be
the biggest challenge later on. The game logic, implemented as a loop in both C
and Python, needs to be implemented using a different mechanism.

My plan is to implement the board logic, consisting of the five components
stated above, in the next couple of days in Haskell. I'll write an article
describing my approach and containing the code for the board logic as soon as I
have a decent solution for the problems stated. The game logic has to wait for a
couple of weeks of even months, depending on my progress with _Programming in
Haskell_.

Stay tuned, and feel free to put (maybe needed?) pressure on me, when those
articles do not appear any time soon…
</content>
    </entry>
    <entry>
        <title>Virtual Machines with libvirt and Networking</title>
        <link href="https://paedubucher.ch/articles/2020-08-01-virtual-machines-with-libvirt-and-networking.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-08-01-virtual-machines-with-libvirt-and-networking.html</id>
        <updated>2020-08-01T22:30:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
I'd like to dig deeper into system administration tasks. At work, I have to
manage a fleet of Linux servers with Puppet. And in my spare time, I'd like to
manage the servers I run with Ansible or Puppet in the future.

Virtual Machines are easily obtained nowadays. Cloud providers such as Digital
Ocean or Exoscale offer virtual machines with various operating systems at
rather moderate prices. You only have to pay for the time the virtual machines
are actually running, so you can save money by shutting those hosts down when
not needed.

However, running those virtual machines locally costs even less. No additional
public IPv4 addresses are wasted, and, most importantly, a local setup allows
you to test changes to be applied to your productive environment locally
beforehand.

This article shows how to set up three virtual machines ‒ `master`, `node1`, and
`node2`, which later could be used for a Puppet setup with a Puppetmaster ‒
using [libvirt](https://libvirt.org/) on top of
[KVM](https://www.linux-kvm.org/page/Main_Page). [Debian 10
(«Buster»)](https://www.debian.org/releases/buster/) is going to be used both as
the host and guest operating system. The host operating system is installed on a
Dell Latitude E6430 from 2013 with 8 GB or RAM, which is just laying around
here. (This also proofs that you don't need a whole lot of hardware resources
for such a setup.)

# Setting up the Virtualization

Given a fresh Debian setup with the lightweight LXQt desktop, a couple of
packages need to be installed in order to get virtualization to work:

    # apt-get install \
        qemu-kvm \
        libvirt-clients \
        libvirt-daemon-system \
        virtinst \
        bridge-utils

Make sure to activate virtualization in the BIOS. Check if the `kvm` kernel
module is activated:

    $ lsmod | grep ^kvm
    kvm                 835584  1 kvm_intel

If there is a number not equal to 0 in the third column, `kvm` is up and
running.

# Setting up the Virtual Network

Usually a `default` network is pre-defined, which can be checked as follows:

    # virsh net-list --all
     Name      State      Autostart   Persistent
    ----------------------------------------------
     default   inactive   no          yes

The `default` network can be configured to be started up automatically:

    # virsh net-autostart default
    Network default marked as autostarted

Until the next system restart, it is started up manually:

    # virsh net-start default
    Network default started

A bridge interface `virbr0` should have been created:

    # brctl show
    bridge name     bridge id               STP enabled     interfaces
    virbr0          8000.5254005f4e6b       yes             virbr0-nic

Make sure that NAT is activated:

    # sudo sysctl -a | grep 'net.ipv4.ip_forward ='
    net.ipv4.ip_forward = 1

The value of the above property must be `1`.

## Possible Issues

If `iptables` is in use, make sure to forward the traffic from the guests over
the bridge `virbr0`, so that the guests also have internet access:

    # iptables -I FORWARD -i virbr0 -o virbr0 -j ACCEPT

# Setting up the Virtual Machines

Since networking over the bridge interface requires `root` privileges, all
virtual machine files are put into the `/opt/vms` directory, which first needs
to be created:

    # mkdir /opt/vms
    # cd /opt/vms

The network installer for Debian Buster can be downloaded from the official
website:

    # wget https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/\
    debian-10.4.0-amd64-netinst.iso

The `master` virtual machine is now setup using `virt-install`:

    # virt-install \
        --name master \
        --memory 1024 \
        --vcpus=1,maxvcpus=2 \
        --cpu host \
        --cdrom debian-10.4.0-amd64-netinst.iso \
        --disk /opt/vms/master.qcow2,size=8,format=qcow2 \
        --network network=default \
        --virt-type kvm

The machine gets 1 GB of memory and a 8 GB disk. Most importantly, the network
is set to the `default` network.

A window showing the Debian installer appears. Just install the standard system
utilities and the SSH server. The following users and passwords shall be
configured:

- `root`: `topsecret`
- `user`: `secret`

After the setup is finished, just let the system boot, and login as `root`. Then
shut the virtual machine down:

    # shutdown -h now

The two additional guest nodes can be created by cloning the `master` virtual
machine just set up:

    # virt-clone --original master --name node1 --file node1.qcow2
    # virt-clone --original master --name node2 --file node2.qcow2

Now start up all the nodes:

    # virsh --connect qemu:///session start master
    # virsh --connect qemu:///session start node1
    # virsh --connect qemu:///session start node2

# Configuring the Virtual Network

In order to conveniently access the guests, static IPs should be assigned to
them. The network configuration can be edited as follows:

    # virsh net-edit default

An editor showing an XML configuration appears:

    &lt;network&gt;
      &lt;name&gt;default&lt;/name&gt;
      &lt;uuid&gt;fecb90d5-9b46-48f6-8b93-e57032f8ba6a&lt;/uuid&gt;
      &lt;forward mode='nat'/&gt;
      &lt;bridge name='virbr0' stp='on' delay='0'/&gt;
      &lt;mac address='52:54:00:63:d3:70'/&gt;
      &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;
        &lt;dhcp&gt;
          &lt;range start='192.168.122.2' end='192.168.122.254'/&gt;
        &lt;/dhcp&gt;
      &lt;/ip&gt;
    &lt;/network&gt;

The `dhcp` section needs to be extended with static IP definitions, which map
the MAC addresses of the guest's virtual network interfaces to the static IP
addresses to be used.

The MAC addresses of the virtual machines can be extracted from their
configuration as follows:

    # virsh dumpxml master | grep -i '&lt;mac'
        &lt;mac address='52:54:00:db:07:7c'/&gt;
    # virsh dumpxml node1 | grep -i '&lt;mac'
        &lt;mac address='52:54:00:a4:77:a9'/&gt;
    # virsh dumpxml node2 | grep -i '&lt;mac'
        &lt;mac address='52:54:00:51:e8:ef'/&gt;

Using those MAC addresses, new static host definitions can be created as
follows:

    &lt;host mac='52:54:00:db:07:7c' name='master' ip='192.168.122.2'/&gt;
    &lt;host mac='52:54:00:a4:77:a9' name='node1' ip='192.168.122.3'/&gt;
    &lt;host mac='52:54:00:51:e8:ef' name='node2' ip='192.168.122.4'/&gt;

The XML network definition should now look as follows (the `uuid` and `mac
address` of the host will vary):

    &lt;network&gt;
      &lt;name&gt;default&lt;/name&gt;
      &lt;uuid&gt;fecb90d5-9b46-48f6-8b93-e57032f8ba6a&lt;/uuid&gt;
      &lt;forward mode='nat'/&gt;
      &lt;bridge name='virbr0' stp='on' delay='0'/&gt;
      &lt;mac address='52:54:00:63:d3:70'/&gt;
      &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;
        &lt;dhcp&gt;
          &lt;range start='192.168.122.2' end='192.168.122.254'/&gt;
          &lt;host mac='52:54:00:db:07:7c' name='master' ip='192.168.122.2'/&gt;
          &lt;host mac='52:54:00:a4:77:a9' name='node1' ip='192.168.122.3'/&gt;
          &lt;host mac='52:54:00:51:e8:ef' name='node2' ip='192.168.122.4'/&gt;
        &lt;/dhcp&gt;
      &lt;/ip&gt;
    &lt;/network&gt;

After saving the configuration, the network `default` needs to be restarted:

    # virsh net-destroy default
    # virsh net-start default

The guest virtual machines must also be restarted so that they will get the new
IP addresses assigned:

    # virsh shutdown master
    # virsh shutdown node1
    # virsh shutdown node2

    # virsh --connect qemu:///session start master
    # virsh --connect qemu:///session start node1
    # virsh --connect qemu:///session start node2

The virtual machines should now be accessible through SSH:

    $ ssh user@192.168.122.2
    $ ssh user@192.168.122.3
    $ ssh user@192.168.122.4

Make sure that the network communication is working between the guests:

    [user@master]$ ping node1
    [user@master]$ ping node2

Also make sure to define the proper hostname in `/etc/hostname`, for it is still
`master` for the two guests that have been cloned from the initial image:

    [root@node1]# echo 'node1' &gt; /etc/hostname
    [root@node2]# echo 'node2' &gt; /etc/hostname

## Adding Some Comfort

Consider adding the following definitions to `/etc/hosts`:

    192.168.122.2   master
    192.168.122.3   node1
    192.168.122.4   node2

So that you can access your virtual machines by their host names:

    $ ssh user@master
    $ ssh user@node1
    $ ssh user@node2

In order to login to the guests without typing a password, create an SSH key
locally without any passphrase:

    $ ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_vms_rsa

Make sure that your `~/.ssh` folder has the access mode `700`, and the contained
files all have the access mode `600` (thanks to [meillo](http://marmaro.de/) for
pointing that out):

    $ chmod 700 ~/.ssh
    $ chmod 600 ~/.ssh/*

Copy the public key to the hosts using `ssh-copy_id` (thanks to meillo again for
hinting that utility to me):

    $ ssh-copy-id -i ~/.ssh/id_vms_rsa user@master
    $ ssh-copy-id -i ~/.ssh/id_vms_rsa user@node1
    $ ssh-copy-id -i ~/.ssh/id_vms_rsa user@node2


Check that the SSH connection now works without any password:

    $ ssh -i ~/.ssh/id_vms_rsa user@master
    $ ssh -i ~/.ssh/id_vms_rsa user@node1
    $ ssh -i ~/.ssh/id_vms_rsa user@node2


# Conclusion

Three virtual machines running Debian GNU/Linux have been installed on a
rather old laptop running Debian GNU/Linux itself. Those virtual machines can be
comfortably accessed without any passwords through SSH, and are able to
communicate with one another over a virtual network.

It took me almost a day ‒ and gave me some additional grey hair ‒ to get all
this information together from various sources. After I figured out how to
create the setup described above, it only took me about two hours to reproduce 
everything on another laptop (including the setup of the laptop itself) and to
write this article.

Since I did the try-and-error part on Arch Linux, this article can also be used
on that distribution, and probably many others as well. Only the packages to be
installed will probably vary on other distributions.

I plan to describe the setup of a local Puppet environment based on the setup
described above in a forthcoming article.
</content>
    </entry>
    <entry>
        <title>Table-Driven Test Design</title>
        <link href="https://paedubucher.ch/articles/2020-07-22-table-driven-test-design.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-07-22-table-driven-test-design.html</id>
        <updated>2020-07-22T22:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
Many universities teach programming in Java. Writing unit tests is one of the
subjects being taught. Many professional Java programmers, but also university
professors, suggest to build those test cases according to a pattern. _Given,
When, Then_ is a common pattern, and so is _Arrange, Act, Assert_. Both patterns
prescribe the following structure for a test case:

1. _Given_/_Arrange_: An environment (in the broadest sense) is built up.
2. _When_/_Act_: The function or method to be tested is invoked.
3. _Then_/_Assert_: The result of the function or method is checked against some
   expectation.

Such a test case might look as follows (Java):

    public void testAddition() {
        // Given/Arrange
        Calculator calc = new Calculator();
        int a = 3;
        int b = 5;

        // When/Act
        sum = calc.add(a, b);

        // Then/Assert
        assertEqual(8, sum);
    }

A rule often taught is the so-called _single assert rule_ from Robert C. Martin,
[whom I refuse to call «Uncle
Bob»](http://marmaro.de/apov/txt/2016-04-27_schaedlicher-kult.txt). It states
that there should be only one assertion per test case. One can argue whether or
not this rule is useful.

# Unclean Code

However, in my experience this rule leads to a consequence I do not like ‒ and
which also doesn't fit into the _Clean Code_ philosophy (or _cult_, I daresay):
The programming language being used to write test code is a small subset of the
implementation language, often degenerating into a sheer sequence of statements
(imperative programming).

Even though using a subset of a language is often a sensible approach (just
think about C++, or `with` and `eval` in JavaScript, or `unsafe` in Go, etc.),
using a subset of a language that doesn't even contain core features from
structured programming (decisions, loops, data structures) does not sound
sensible to me, except when programming in a purely functional style.

How should an additional test case to cover, say, negative numbers, be added to
the one above? The _single assert rule_ wants us to write an additional test
case:

    public void testAdditionWithNegativeNumbers() {
        // Given/Arrange
        Calculator calc = new Calculator();
        int a = -1;
        int b = 3;

        // When/Act
        sum = calc.add(a, b);

        // Then/Assert
        assertEqual(2, sum);
    }

Who would _type_ in that code, which is almost identical to the one above? Such
code is rather _copied_ than written again. (Why don't I hear somebody shouting
_«Clean Code!!!!11»_ now?)

# Structured Programming to the Rescue

Let's violate the _single assert rule_ for a minute and bring back structured
programming. Let's write a unit test in C!

    typedef struct {
        int a;
        int b;
        int expected;
    } addition_test_case;

    void test_addition()
    {
        addition_test_case tests[] = {
            {3, 5, 8},
            {-1, 3, 2},
        };
        int n = sizeof(tests) / sizeof(tests[0]);
        for (int i = 0; i &lt; n; i++) {
            addition_test_case test = tests[i];
            int actual = add(test.a, test.b);
            if (actual != test.expected) {
                printf(&quot;add(%d, %d): expected %d, got %d\n&quot;,
                        test.a, test.b, test.expected, actual);
                exit(1);
            }
        }
        printf(&quot;test_addition: %d tests passed\n&quot;, n);
    }

This test case, which does not make use of any unit testing framework, was
designed in a _table-driven_ manner. I first got to know the concept of
_table-driven test design_ when learning Go by reading [The Go Programming
Language](http://www.gopl.io/) (p. 306) by Alan A. A. Donovan and the great
Brian W. Kernighan.

However, the concept must predate Go, for I can at least remember one article by
Rob Pike, who later designed Go, mentioning table-driven test design.
(Ironically ‒ or not so ironically ‒ that article was a critique of
object-oriented programming, as far as I can remember.)

# Table-Driven Test Design

Let's break down the parts that make up a table-driven test design.

First, a single test case is defined using a structure that contains all the
input parameters, and the expected result of the test:

    typedef struct {
        int a;
        int b;
        int expected;
    } addition_test_case;

Second, an array ‒ the test _table_ ‒ containing all the test definitions is
defined (_Given_/_Arrange_):

    addition_test_case tests[] = {
        {3, 5, 8},
        {-1, 3, 2},
    };

Third, the test table is processed using a _loop_ (structured programming,
remember that?):

    int n = sizeof(tests) / sizeof(tests[0]);
    for (int i = 0; i &lt; n; i++) {
        // omitted
    }

For every test case, the result is computed (_Act_/_When_):

    addition_test_case test = tests[i];
    int actual = add(test.a, test.b);

Fourth, the result is validated against the definition (_Then_/_Assert_):

    if (actual != test.expected) {
        printf(&quot;add(%d, %d): expected %d, got %d\n&quot;,
                test.a, test.b, test.expected, actual);
        exit(1);
    }
    printf(&quot;test_addition: %d tests passed\n&quot;, n);

An error message is printed if the `actual` value is not equal to the `expected`
value (in case `add` was implemented incorrectly):

    add(3, 5): exptected 8, got 666

Note that this test terminates after the first error. No assertions are used.
The lack of a test framework is compensated by manually defined error and
success messages.

Yes, I'm well aware of the fact that there are unit testing libraries in C. The
point is that this C code covering two test cases is only slightly longer than
the Java code to cover the same amount of test cases would be. (Using Python or
Go rather than C would have shaved off some additional lines.)

Now let's add a third and a fourth test case:

    addition_test_case tests[] = {
        {3, 5, 8},
        {-1, 3, 2},
        {13, 17, 30}, // new
        (-100, 100, 0}, // new
    };

No code was copied. No existing code was modified. Only _two_ lines of code were
added to define _two_ additional test cases. The table-driven test is
_extensible_.  Robert C. Martin would love it, wouldn't he?

# Comparing Apples to Rotten Tomatoes

So why isn't everybody writing table-driven tests instead of triple-A copy-paste
tests?

First, some programming languages make it harder to define data structures as
literals. Languages like JavaScript, Python, or Go are quite good at that. Even
C, as shown above, can be quite concise when it comes to defining static data
structures. Java recently got better at that, but up to version 8, defining a
static map structure was done by adding single elements subsequently. (Why don't
I hear _«DRY principle!!!1»_ now?)

Second, the unit testing framework plays an important role. In C, (at least as
shown above), and in Go (as it is done using the standard library), no
assertions are used. The programmer instead performs the checks manually and
reacts with a reasonable error message. The programmer is supposed to _program_
the tests.

Some unit testing frameworks that do make use of assertions also allow to add
custom error messages to every `assert` call. Other frameworks, such as
[Jest](https://jestjs.io/), just will tell you _on which line_ an assertion
failed. This is not very useful when having assertions within a loop, for the
programmer does not know which test case failed. At least for Jest, writing pure
sequential assertion code is a necessity, and the _single assert rule_ looks
quite reasonable from that perspective.

The [PyTest](https://docs.pytest.org/en/latest/) framework, for example, has
table-driven test design built-in, by providing the static test definitions
through a decorator, which is basically an annotation in Java lingo. (Check
`@pytest.mark.parametrize` for details.) However, this approach makes it
impossible to include information into the test table that needs prior
construction within the test function.

More recent versions of JUnit also allow for parametrized tests (check out the
`@ParametrizedTest` and `@ValueSource` annotations). The restrictions stated
above for PyTest also apply here. Again, the poor programmer is put into
straightjacket, for he's not supposed to _program_, but only to _test_.

My favourite test framework is from the Go standard library, which on one hand
gives the programmer total flexibility, and on the other hand provides an useful
API to construct small but powerful test runners. Checkout the
[testing](https://golang.org/pkg/testing/) package for details. (And read [The
Go Programming Language](https://gopl.io) by all means, even if you don't need
to learn Go. You'll pick up a lot about computer science in this book.)

# Single Assert Rule Revisited

The discussion about testing frameworks and programming languages (and text
editors, and tabs vs. spaces) could be extended here ad nauseam. But let's
review the _single assert rule_ instead, which could be interpreted from two
perspectives:

1. Runtime: `assert` should only be called once per execution of every test
   function/method.
2. Code: There should only be one reference to `assert` in every test
   function/method.

While the first interpretation makes table-driven design impossible, the second
interpretation might be closer to the rule's original intention: Each test case
should only verify one aspect of the function/method being called.

I'll therefore continue to happily violate the first interpretation of the rule,
for the advantages of table-driven test design (extensibility, flexibility, more
concise code) outhweigh the indiscriminate application of some hand-wavy
statements about «doing only one thing» by far. Please let me just _program_
those tests…

As an additional example, check out my test cases for some time formatting
routines
([test_timefmt.c](https://github.com/patrickbucher/countdown/blob/master/test_timefmt.c)).
Here, the test table can be used in two directions: One function uses the left
value as input and the right value as the expected outcome, while the other
function does the opposite. Here, _two_ new test cases are defined by adding
_one_ (very short) line of code.

Am _I_ allowed to shout _«Clean Code!»_ and _«DRY principle!»_ now, by the way?
</content>
    </entry>
    <entry>
        <title>Optimierung und Externalisierung</title>
        <link href="https://paedubucher.ch/articles/2020-07-04-optimierung-und-externalisierung.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-07-04-optimierung-und-externalisierung.html</id>
        <updated>2020-07-04T15:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
Ich habe diesen Frühling _Heute schon einen Prozess optimiert?_ von Gunter Dueck
gelesen. Der Autor beschreibt in diesem Buch, wie in Deutschland (und im
ähnlichen Stil wohl auch in anderen Ländern) derzeit Prozessoptimiertung überall
das Gebot der Stunde ist. Historisch gesehen habe man das Wirtschaftswachstum
seit dem zweiten Weltkrieg vor allem Prozessoptimierungen im zweiten
Wirtschaftssektor (Industrie) zu verdanken. Die Autos, die wir heute fahren,
unterscheiden sich nicht grundlegend von denjenigen, die vor 50 Jahren
produziert worden sind. Ihre Herstellungsweise hat sich jedoch radikal
verändert und läuft heute grösstenteils automatisch ab.

In der Industrie sind wir mittlerweile an die Grenzen der Optimierung und des
Wachstums geraten. Grosses Wachstum gibt es nur noch im Dienstleistungssektor.
Das Problem, das Dueck beschreibt, bezieht sich auf die Dienstleistungen. Denn
hier wird genau nach dem gleichen Prinzip verfahren wie in der Industrie:
Prozessoptimierung, was das Zeugs hält! Doch sind optimierte Dienstleistungen
wirklich das, was sich der Kunde wünscht?

McDonald's ist das Paradebeispiel für Prozessoptimierung in der Gastronomie. Ich
esse sehr selten dort, und das praktisch nur, wenn es keine Alternativen gibt,
und/oder wenn ich betrunken bin. Die Bedienung erfolgt hocheffizient. Dank der
neuen Bestell- und Bezahlterminals muss man nicht einmal mehr lange an der Kasse
anstehen und sich dort mit dem Personal unterhalten. Der Bestellprozess ist
mittlerweile soweit durchoptimiert, wie es der Herstellungsprozess in der Küche
schon längstens ist.

Doch möchte ich auch in einem «richtigen» Restaurant so bedient werden? Ich gehe
gerne zwischendurch in der Mittagspause mit Bekannten ausgedehnt in einem
Restaurant essen. Dort steht neben dem guten Essen auch die Unterhaltung im
Mittelpunkt. So eine Mittagspause ist oft bereichernd und entspannend, quasi ein
Kurzurlaub vor dem Nachmittag.

Merke ich jedoch, dass die Bedienung sichtlich gestresst ist, kann ich mich beim
Restaurantbesuch kaum entspannen. Ich wähle und bestelle mein Essen sehr schnell
und versuche, die Bedienung nicht unnötig lange aufzuhalten, denn ansonsten
könnte das Ärger mit dem Vorgesetzten geben, was bloss für noch mehr Stress und
schlechte Laune sorgt. Ein Mittagessen in einem Restaurant, das
Prozessoptimierung betreibt, geht zwar schneller, ist aber kein sehr angenehmes
Erlebnis. Man könnte auch gleich zu McDonald's gehen.

Ein anderes Beispiel ist die Zustellung von Paketen. In den 90er-Jahren kam
einmal täglich ein Postbote vorbei, der auf einem kleinen Anhänger Pakete
mitführte. Für ein Dorf mit den weit ausserhalb gelegenen Bauernhöfen waren
meistens ein oder zwei Postboten verantwortlich. Zu dieser Zeit gab es
wesentlich weniger Pakete, jedoch mehr Briefe, Zeitungen, Zeitschriften usw.

Diese Postboten haben immer einen sehr entspannten Eindruck auf mich gemacht.
Oft konnte ich beobachten, dass sich der Postbote nach der Brief- und
Paketzustellung noch mit den Nachbarn unterhielt, bis er zum nächsten Haus
weiterzog. Offensichtlich hatte man damals noch Zeit…

Heutzutage ist Effizienz angesagt. Der Paketbote rennt aus seinem Kastenwagen
und will siene Ware möglichst schnell loswerden. Das ist auch nötig, denn seine
Route wurde zuvor nach tayloristischen Methoden vermessen. Die Post weiss, wie
lange der Bote für welche Anzahl Pakete maximal benötigen darf. Wird diese
Zielvorgabe nicht eingehalten, hat der Bote mit negativen Konsequenzen zu
rechnen.

Manche Paketzusteller, denn es gibt ja mittlerweile Konkurrenz zur Post,
klingeln sich so oft bei einem Mehrfamilienhaus durch. Schliesslich muss die
Sendung nicht unbedingt dem Empfänger übergeben, sondern nur in das Gebäude
hineingebracht werden. Der Bote klingelt also bei allen Hausbewohnern, und
unterbricht dabei möglicherweise eine Vielzahl von Personen bei ihrer
Beschäftigung. In den letzten Monaten könnte das durchaus Büroarbeit (in meinem
Fall Softwareentwicklung) gewesen sein, zumal viele Leute im Home-Office tätig
sind. Wie schädlich solche Unterbrechungen sein können, weiss ich als
Programmierer nur zu gut.

Ergebnis: Durch die Unterbrechungen sind die Leute weniger produktiv. Ihre
Arbeitgeber verlieren Arbeitsleistung und damit Geld, müssen ihre Angestellten
aber genau gleich entlöhnen. Der Paketzusteller spart hingegen einen Bruchteil
seiner Personalkosten, da der Zustellungsprozess mittels Durchklingeln optimiert
worden ist. Der Paketzusteller externalisiert seine Kosten ‒ das Umfeld hat
diese zu bezahlen.

Diese Prozessoptimierung führt nicht nur zu schlechteren Dienstleistungen ‒ das
Paket wurde unsanft beim Eingang abgeworfen, und nicht dem Empfänger überreicht
‒ sondern auch zu externalisierten Kosten. Denn der entstandene Schaden taucht
nicht in der Bilanz des Paketzustellers auf, jedenfalls nicht sofort. (Und
sollten die Versandhändler wegen schlechter Rückmeldungen der Logistikfirma ihre
Aufträge entziehen, dürfte diese zum Ausgleich wiederum mit weiteren
Prozessoptimierungen reagieren.)

Ich bin keinesfalls gegen die Automatisierung von mechanischen Abläufen, denn
diese ist als Softwareentwickle mein täglich Brot, ja meine
Existenzberechtigung. Es gibt Aufgaben, die der Computer schneller und präziser
ausführen kann als ein Mensch. Die zwischenmenschlichen Interaktionen sollten
jedoch nicht optimiert werden, denn diese machen oftmals die Qualität einer
Dienstleistung aus. Solche Optimierungen führen oft bloss zu Frust auf beide
Seiten ‒ und eben zu externalisierten Kosten, von denen wir sonst schon viele
haben (Umweltverschmutzung, Lärmbelastung, Littering usw.)

Fazit: Wir sollten beim Optimieren von Prozessen nicht nur darauf achten, dass
dabei die Dienstleistung und der zwischenmenschlicher Umgang nicht
beeinträchtigt werden. Wir sollten auch darauf achten, dass wir unsere
Einsparungen nicht unseren Mitmenschen als externalisierte Kosten aufbürden.
</content>
    </entry>
    <entry>
        <title>Meine Linux-Distributionen</title>
        <link href="https://paedubucher.ch/articles/2020-06-28-meine-linux-distributionen.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-06-28-meine-linux-distributionen.html</id>
        <updated>2020-06-28T22:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
Ich verwende seit 2005 hauptsächlich Linux als Betriebssystem. Dabei habe ich
schon Erfahrungen mit verschiedenen Distributionen sammeln können. Meistens
hatte ich eine Hauptdistribution, die ich praktisch auf all meinen Rechnern
installiert war. Dies ändert sich jetzt vielleicht. Doch der Reihe nach…

# Mandrake: Wie alles begann

Meine ersten Erfahrungen mit Linux habe ich im Jahr 2004 gemacht. Alles begann
damit, dass eMule (das damals wichtigste File-Sharing-Tool, das einen
Stellenwert hatte, wie es heute BitTorrent hat) auf dem Windows-Rechner der
Familie nicht mehr richtig funktionierte. Irgendetwas musste ich am
Betriebssystem kaputt gemacht haben.

Eine mögliche Lösung wäre es gewesen, den Rechner neu mit Windows XP
aufzusetzen. Das konnte ich aber nicht so einfach tun, da auch andere
Familienmitglieder Dateien auf dem Rechner hatten. So musste ich immer um
Erlaubnis bitten, wenn ich den Rechner neu aufsetzen wollte. Ausserdem dauerte
es oft Tage, bis wieder alles funktionstüchtig war.

Da ich eine zweite Festplatte hatte, die ich sonst für nichts brauchte, wollte
ich stattdessen einen Dual-Boot einrichten. So gab ich _Mandrake Linux_ (heute
_Mandriva_) eine Chance. Die Installation lief problemlos ab, und auch der Dual
Boot mit Windows klappte problemlos. Meine Familie konnte weiter standardmässig
nach Windows booten.

Die KDE-Oberfläche war für mich einfach bedienbar. Da ich bereits auf Windows
diverse OpenSource-Programme (OpenOffice.org, VLC Media Player, Firefox)
verwendete, kam ich recht schnell mit dem Betriebssystem zurecht. eMule lief
tatsächlich unter Mandrake. Das Problem war aber, wie ich die heruntergeladenen
Dateien vom Rechner wegkopieren sollte.

Der USB-Stick (Kapazität: 128 MB), den ich an einem überbetrieblichen Kurs
(Computer zusammenbauen) erhalten hatte, wurde nicht automatisch erkannt. Und
das mit dem `mount`-Befehl, was von der Google-Suche ausgespuckt worden war,
überforderte mich dann doch noch. Der Zugriff auf die Windows-Festplatte (NTFS)
funktionierte (out of the box) leider nur lesend. So werde ich mir wohl die
heruntergeladenen Dateien auf CDs gebrannt haben, denn die Brennsoftware
funktionierte problemlos.

Ansonsten verlor ich bald das Interesse an Mandrake und bootete nur noch nach
Windows.

# SuSE: Linux als neues Zuhause

Es muss wohl Ende 2004 oder Anfang 2005 gewesen sein, als ich mir zum ersten mal
SuSE installierte. Wahrshceinlich war es Version 9.2 oder 9.3. Wieder
installierte ich es auf der zweiten Festplatte neben Windows. Doch dieses mal
sollte ich dabei bleiben.

Im Sommer 2005 wechselte ich nach zwei Jahren Lehrlingsaustausch bei der [Data
Unit AG](https://www.dataunit.ch) in die Softwareentwicklung bei [Bison Schweiz
AG](https://www.bison-group.ch). Nach zwei eher Microsoft-geprägten Jahren
sollte ich nun also ein Java-Entwickler werden. In der Schule arbeiteten wir mit
C#. Doch unser Lehrer in den Programmierfächern, Roland Bucher, der beide
Programmiersprachen kannte, war so flexibel, dass er uns die Wahl der
Programmiersprache frei liess. So rückte ich ab von C# und beschäftigte mich
bereits im zweiten Lehrjahr, also bevor ich den Arbeitsplatz wechselte, mit
Java.

Es muss kurz vor diesem Wechsel gewesen sein, als ich auf
[Heise.de](https://www.heise.de) einen Artikel über die Zukunftsstrategie von
Microsoft gelesen hatte. Dabei kündigte der damalige CEO Steve Ballmer an, dass
Microsoft so etwas wie _full spectrum dominance_ in der IT erreichen wollte. Das
Forum zu dieser News-Meldung war damals voller ablehnender Beiträge. Microsoft
wurde zu dieser Zeit vom unsympathischen Monopolisten zum absoluten Hassobjekt,
und das nicht nur für mich. Für mich war klar, dass ich von Microsoft und damit
von Windows weg musste.

Es kam dazu, dass ich die Dokumentation [The
Code](https://www.youtube.com/watch?v=XMm0HsmOTFI) gesehen hatte. Nun
interessierte ich mich nicht nur für GNU/Linux als Betriebssystem, sondern für
die Freie-Software-Bewegung als Ganzes. Für mich war eine neue Welt aufgegangen.
Leute wie Richard Stallman, Linus Torvalds und Alan Cox waren meine neuen Idole.

Im Herbst 2005 hatten wir in der Lehre unsere Zwischenprüfungen (pardon:
Teilabschlussprüfungen). Hierfür habe ich mit einer Gruppe von fünf
Klassenkameraden einige Zusammenfassungen geschrieben. Diese sind immer noch
in einem [Archiv](https://github.com/patrickbucher/archive/tree/master/pdfs) auf
GitHub zu finden. Wir nannten uns damals «Team Eichhof». (Das würde ich heute
auch nicht mehr machen…) All diese Dokumente wurden in OpenOffice.org
geschrieben. Ich war der einzige von uns sechs, der das verwendete. Ich weiss
nicht einmal mehr genau, wie ich die Beiträge meiner Kollegen eingebunden hatte.
Wahrscheinlich habe ich sie aus den Word-Dokumenten der Kameraden rauskopiert.

Die meiste Zeit war ich nun auf Linux unterwegs, wobei ich diese
Zusammenfassungen natürlich auch unter Windows hätte bearbeiten können. Wichtig
war, dass mein jeweils aktuelles Arbeitsverzeichnis nun auf der Linux-Festplatte
lag. Beim Dual Boot wählte ich nun immer seltener Windows aus.

Sollten die Zwischenprüfungen problemlos ablaufen, und sollte ich alles
bestehen, wollte ich mir meinen ersten eigenen Computer zur Belohnung kaufen.
Natürlich würde ich mir den selber zusammenbauen, und bloss die Komponenten dazu
kaufen. Wichtig war, dass die Komponenten alle gut von Linux unterstützt wurden.
Das war damals beispielsweise bei WiFi-Karten gar nicht selbstverständlich. Und
da der Computer in meinem Zimmer stehen sollte, war ein Ethernet-Kabel leider
keine Option.

Ein Berufsschulkollege, der schon seit frühem Jugendalter mit Linux arbeitete,
und auch bereits seine eigene Firma hatte, war hierfür ein guter
Ansprechpartner. Ich bestellte die Hardware bei ihm. (Die Prüfungen waren
übrigens sehr gut gelaufen.) Ich staunte sehr, dass er mir die Komponenten mit
seinem eigenen Firmenauto lieferte.

Den Computer hatte ich bald zusammengebaut. Doch leider liess sich SuSE Linux
darauf nicht installieren ‒ oder zumindest funktionierte das WiFi nicht, so
genau kann ich mich nicht mehr darain erinnern. Auf jeden Fall gab es ein
Problem mit SuSE. So habe ich einen Plan B gebraucht.

# Ubuntu: Ein gelungener Umstieg

Zu dieser Zeit wurde gerade _Ubuntu_ einigermassen populär. Ich war zwar auf
SuSE ein begeisterter KDE-Benutzer und hätte darum auch zu _Kubuntu_ wechseln
können. Ich wollte aber doch lieber das «Original» einmal ausprobieren.

Ubuntu liess sich problemlos installieren. Ich weiss nicht mehr, ob es _Breezy
Badger_ (5.10, am 12. Oktober 2005 erschienen) oder die Vorgängerversion _Hoary
Hedgehog_ (5.04, am 8. April 2005 erschienen) war. Auf jeden Fall funktionierte
alles auf Anhieb, auch das WiFi.

An GNOME gewöhnte ich mich sehr schnell. Es war übersichtlicher und eleganter
als KDE. Es funktionierte alles so, wie es musste. Aus dieser Zeit ist mir
ansonsten eher wenig geblieben.

Ab und zu musste ich wohl auch noch am Windows-Rechner arbeiten, denn in der
Berufsschule wurde immer noch der Microsoft-Stack unterrichtet. _Microsoft SQL
Server_ habe ich mit Sicherheit einmal verwenden müssen. Geblieben ist mir davon
wenig. Die gleichen Übungen hätte man auch mit MySQL oder PostgreSQL machen
können.

2006 kaufte ich mir dann sogar einen eigenen Laptop. Der Lehrlingslohn war ja
mit dem dritten Lehrjahr bedeutend angestiegen. Das HP-Notebook hatte einen
verspiegelten Bildschirm. (Diesen Fehler würde ich heute nicht mehr machen.)
Doch Ubuntu lief darauf problemlos. Ich konnte den Laptop auch in die Schule
mitbringen und darauf arbeiten. Aber ans Netzwerk durfte ich ihn nicht
anschliessen, aus Sicherheitsgründen, versteht sich. Eine externe USB-Festplatte
diente zum Dateiaustausch.

So bin ich bis zum Lehrabschluss bei Ubuntu geblieben. Für die
Lehrabschlussprüfungen haben wir wieder in der gleichen Gruppe wie zwei Jahre
zuvor Zusammenfassungen geschrieben. Dieses mal nicht mehr als «Team Eichhof»,
aber wiederum mit OpenOffice.org. Die Zusammenfassung für die Allgemeinbildung
hatte ich selbständig mit LaTeX verfasst. (Diese war Jahre später noch einem
Lehrling hilfreich, sodass sich dieser per E-Mail bei mir bedankte.)

# Debian: Ubuntu für Erwachsene

2009 kaufte ich mir gleich zwei Computer. Einerseits einen Dell OptiPlex als
Computer für mein Zimer, und andererseits ein Lenovo Thinkpad (mit grosszügigem
Studentenrabatt) für mein Informatik-Studium.

Ich weiss nicht mehr, ob Ubuntu auf einem der beiden Rechnern nicht
funktionierte. Auf jeden Fall stieg ich in dieser Zeit auf Debian um, das den
Ruf hatte, schwer installierbar zu sein. Tatsächlich waren es einfach ein paar
Klicks mehr im Setup-Menü als bei Ubuntu.

Auf meinem Laptop hatte ich einen Dual Boot eingerichtet, da ich ja im
Informatikstudium weiterhin würde Windows verwenden müssen. (Daran hat sich bis
heute kaum etwas geändert.)

Von Ubuntu her waren mir viele Konzepte für Debian schon bekannt, zumal ja
Ubuntu auf Debian basiert. Den Paketmanger `apt-get` verwendete ich auch über
die Kommandozeile, und kaum noch über ein grafisches Tool, dessen Name mir
entfallen ist.

Ich arbeitete nun schon seit etwa fünf Jahren mit Linux, war aber nur ein
Anwender, und keinesfalls ein Profi. Wenn ich etwas auf der Kommandozeilen
machen musste, dann kopierte ich mir diese Befehle von einer Webseite, und
hoffte, dass sie funktionieren würde. Ich war auch weiterhin in der alten
Windows-Routine verhaftet, dass ich das Betriebssystem komplett neu
installierte, wenn etwas grundsätzliches nicht mehr funktionierte. Verstanden
habe ich vom System sehr wenig.

Zu dieser Zeit verlor ich auch die Lust an der Informatik. Der Grund dafür
dürfte eine Kombination aus meiner Situation in Beruf und Hochschule gewesen
sein, wobei auch der Mangel an Freizeit über mehrere Jahre (Berufsmatura,
Studium) mit Lektionen am Samstag, an den Abenden und Lernen am Wochenende auch
eine Rolle gespielt haben dürfte.

Ich entschloss mich dazu, mein Informatikstudium abzubrechen (bzw. offiziell
bloss zu unterbrechen), und die Matura nachzuholen. Ich wollte lieber
Geistes- und Sprachwissenschaften studieren, als mich noch länger mit der
Informatik zu beschäftigen. Zunächst wollte ich aber mein Französisch aufbessern
und ging im Sommer 2010 für einige Wochen nach Paris.

Auf diese Zeit geht auch meine Aversion gegen Bloatware zurück. Ein
Schlüsselerlebnis dürften für mich die Vorträge von [meillo](http://marmaro.de/)
beim Chaos Computer Club Ulm gewesen sein. Schliesslich war es der Window
Manager [dwm](http://dwm.suckless.org/), der mich nachhaltig auf einen anderen
Pfad bringen sollte: Weg vom GUI, hin zur Kommandozeile!

Zunächst verwendete ich weiterhin den GNOME-Login-Bildschirm. Ich schaffte es,
`dwm` als zweite Option (neben dem GNOME-Desktop) zu konfigurieren. So konnte
ich notfalls immer noch auf GNOME ausweichen. Meine grafische Oberfläche war
aber nun `dwm`. Dies hat sich bis heute nicht geändert.

Ich verwendete dieses Setup einige Jahre lang auf meinem Laptop und meinem
Heimrechner. Nun machte ich auch Fortschritte auf der Kommandozeile. Ich
verwendete aber immer noch grösstenteils die Konfigurationstools des Systems.
Für die Netzwerkverbindung war beispielsweise WICD im Einsatz.

In der Zwischenzeit war in meinem Leben einiges passiert: Ich absolvierte die
Passerelle, hatte ein einjähriges Gastspiel in Fribourg, wo ich Slavistik und
Germanistik studierte ‒ und kehrte 2012 dann doch wieder in die Informatik
zurück. Meine Lust am Programmieren hatte ich wohl wiederentdeckt.

In diesen Jahren hatte ich mir auch ein Netbook angeschafft: eine Gattung
Geräte, die von den Tablets verdrängt worden sind. Es muss auf diesem Netbook
gewesen sein, wo ich zum ersten mal ein Betriebssystem ohne GUI installiert
habe. Seither startete ich `dwm` direkt von der Kommandozeile, einen
Login-Screen hatte ich nicht mehr. Diese Installation dokumentierte ich in einem
Artikel namens [Lean Debian](https://web.archive.org/web/20150217043316/http://paedubucher.ch/docs/lean-debian.html).

# Arch: Das vorläufige Ende einer Reise

2016 entschied ich mich dazu, mein Informatik-Studium an der Hochschule Luzern
wieder aufzunehmen und also doch noch zu beenden. Im Sommer hatte ich eine
Aktion entdeckt: einen ultraschwachen Acer-Laptop für 199 Franken mit 32 GB
internem Speicher, der dafür aber extrem leicht und energieeffizient war: der
ideale Laptop fürs Studium!

Die Debian-Installation scheiterte dabei leider. Ich stand wieder vor dem
gleichen Problem, das mich schon früher hat die Distribution wechseln lassen.
Doch mit Debian war ich doch so zufrieden…

Ich probierte verschiedenste Distributionen aus. Einige davon basierten auf _Arch
Linux_. Damit funktionierte alles auf Anhieb, ich hatte aber immer die grafische
Benutzeroberfläche dabei. So wagte ich mich an die manuelle Installation des
«richtigen» Arch Linux heran, wofür ich seither eine personalisierte
[Dokumentation](https://github.com/patrickbucher/docs/blob/master/arch-setup/arch-setup.md)
führe.

Die ganze Sache lief doch recht problemlos ab, sodass ich Arch gleich noch auf
meinem «richtigen» Laptop installierte. (Ich wollte damals diesen Laptop für
Windows brauchen, war aber jetzt zu begeistert von Arch.) Dabei musste ich wohl
vergessen haben, das Mounten der `/boot`-Partition in `/etc/fstab` festzuhalten,
sodass sich der Laptop nach dem nächsten Kernel-Update nicht mehr aufstarten
liess.

Ich verfluchte Linux wie kaum jemals zuvor ‒ und wie seither niemals wieder.
Denn der Fehler war ganz klar auf meiner Seite. Endlich lernte ich etwas übers
System. Das Problem löste ich nicht durch eine komplette Neuinstallation,
sondern indem ich das System mit dem USB-Stick startete und das Mounten der
`/boot`-Partition korrekt konfigurierte. Für mich war das ein Meilenstein.

Im Studium habe ich mich dann weitgehendst an Linux gehalten. Ausnahmen waren
Prüfungen mit dem _Safe Exam Browser_, der eben nur unter Windows und macOS das
System komplett blockieren konnte. In den Modulen _C# in Action_ und
_Microcontroller_ stand auch gezwungenermassen Windows-Einsatz auf dem Programm,
sodass es kaum ein Zufall ist, dass ich diese beiden Module abgebrochen habe.

In der Zwischenzeit arbeitete ich in einer Firma mit macOS. Auf meiner neuen
Stelle kann ich komplett mit Linux arbeiten. Neben Arch Linux auf dem Laptop
kommt auf den Servern Ubuntu zum Einsatz.

# Ausprobiert: Alpine Linux, OpenBSD, FreeBSD

Wenn ich mit Docker-Containern arbeite, ist oft das schlanke _Alpine Linux_
meine Wahl für das Base-Image. Auf einem Heimrechner oder auf einem Laptop habe
ich es bisher noch nicht ernsthaft verwendet. Das dürfte wohl mit der etwas
älteren Kernel-Version zusammenhängen. Auch auf Servern verwende ich es nicht,
da es von vielen Cloud-Anbietern nicht angeboten wird. Dort verwende ich Debian
‒ oder Ubuntu, wenn ich auf neuere Packages angewiesen bin. (Lokal kann man
schon einmal Debian Testing verwenden, das läuft dermassen stabil.)

Weiter habe ich dieses Jahr einige kleinere Ausflüge in die BSD-Welt
unternommen. OpenBSD scheint mir wie geschaffen zu sein für meine Ansprüche:
alles ist minimal, standardmässig sinnvoll konfiguriert und sicher. FreeBSD ist
mir in der Firma begegnet, wo ein Backup-Server (mit ZFS als Dateisystem) damit
läuft.

Für meinen privaten Einsatz konnte sich aber noch keines der beiden Systeme
gegen Arch durchsetzen. Gerade bei Laptops läuft Linux mittlerweile so gut, dass
die BSDs eher ein Rückschritt in vielerlei Hinsicht wäre.

Seit einigen Monaten betreibe ich einen kleinen Server in der Cloud auf Debian.
Hier wäre vielleicht OpenBSD eine sinnvolle Alternative, die ich gelegentlich
prüfen sollte. Überhaupt möchte ich mich gelegentlich stärker mit den BSDs
befassen als mit Linux.

Für die «Hardcore»-Distributionen wie _Gentoo_ und _Linux from Scratch_ konnte
ich mich bisher noch nicht begeistern. Es wären wohl beides gewinnbringende
Übungen.

Im Moment stehen für mich aber andere Themen an, z.B. die funktionale
Programmierung. So bleibe ich vorerst bei Arch Linux, und lasse mich von der
Zukunft überraschen… OpenBSD und FreeBSD laufen mir ja nicht weg.
</content>
    </entry>
    <entry>
        <title>Hallo, Welt!</title>
        <link href="https://paedubucher.ch/articles/2020-06-28-hallo-welt.html"/>
        <author>
            <name>Patrick Bucher</name>
        </author>
        <id>https://paedubucher.ch/articles/2020-06-28-hallo-welt.html</id>
        <updated>2020-06-28T19:00:00Z</updated>
        <content type="text/markdown; charset=UTF-8">
Dies ist ein Demo-Artikel auf meiner neuen Webseite
[paedubucher.ch](http://paedubucher.ch). Die Seite ist mithilfe eines einfachen
statischen Webseiten-Generators erstellt, der auf
[GitHub](https://github.com/patrickbucher/paedubucher.ch) verfügbar ist. Wie
dieser funktioniert, werde ich gerne einmal ausführlicher erklären.

Ich möchte in Zukunft auf meiner Webseite mehr schreiben, auf Deutsch und auf
Englisch, je nach Lust und Laune ‒ und Thema.
</content>
    </entry>
</feed>
